{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = ['similarity_score',\n",
    "                'nn_out',\n",
    "                'last_char',\n",
    "                'avg_shared_words',\n",
    "                'word_count_diff',\n",
    "                'levenshtein',\n",
    "                'shared_words_pcnt',\n",
    "                'avg_shared_trigrams',\n",
    "                'shared_bigram_pcnt',\n",
    "                'shared_trigram_pcnt',\n",
    "                'avg_shared_quadgrams',\n",
    "                'shared_quadgram_pcnt',\n",
    "                'tfidf_word_match_share']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_out = pd.read_csv('../roughfeaturedata/preds_for_logreg.csv')\n",
    "train_features = pd.read_csv('../data/train_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nn_out</th>\n",
       "      <th>id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>last_char</th>\n",
       "      <th>avg_shared_words</th>\n",
       "      <th>word_count_diff</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>shared_words_pcnt</th>\n",
       "      <th>avg_shared_trigrams</th>\n",
       "      <th>shared_bigram_pcnt</th>\n",
       "      <th>shared_trigram_pcnt</th>\n",
       "      <th>avg_shared_quadgrams</th>\n",
       "      <th>shared_quadgram_pcnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004252</td>\n",
       "      <td>28170</td>\n",
       "      <td>Is MPM &amp; Partners in Monaco real?</td>\n",
       "      <td>All those who live in Monaco are fabulously we...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056201</td>\n",
       "      <td>29836</td>\n",
       "      <td>What's the fastest way to get a driver's licen...</td>\n",
       "      <td>How can you get a driver license in your country?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.605505</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009561</td>\n",
       "      <td>208192</td>\n",
       "      <td>How do I integrate 1/ (1+x^4)?</td>\n",
       "      <td>How do I integrate |x|?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.659983</td>\n",
       "      <td>96826</td>\n",
       "      <td>How is Odysseus a bad leader in the Odyssey?</td>\n",
       "      <td>Why was Odysseus considered a good leader in \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.173221</td>\n",
       "      <td>165584</td>\n",
       "      <td>Why was the ending of Aadhe adhoore (Indian Tv...</td>\n",
       "      <td>Why is Indian TV serials too dramatic?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nn_out      id                                          question1  \\\n",
       "0  0.004252   28170                  Is MPM & Partners in Monaco real?   \n",
       "1  0.056201   29836  What's the fastest way to get a driver's licen...   \n",
       "2  0.009561  208192                     How do I integrate 1/ (1+x^4)?   \n",
       "3  0.659983   96826       How is Odysseus a bad leader in the Odyssey?   \n",
       "4  0.173221  165584  Why was the ending of Aadhe adhoore (Indian Tv...   \n",
       "\n",
       "                                           question2  is_duplicate  last_char  \\\n",
       "0  All those who live in Monaco are fabulously we...             0          1   \n",
       "1  How can you get a driver license in your country?             0          1   \n",
       "2                            How do I integrate |x|?             0          1   \n",
       "3  Why was Odysseus considered a good leader in \"...             1          1   \n",
       "4             Why is Indian TV serials too dramatic?             0          1   \n",
       "\n",
       "   avg_shared_words  word_count_diff  levenshtein  shared_words_pcnt  \\\n",
       "0                 2                2     0.470588           0.250000   \n",
       "1                 4                1     0.605505           0.380952   \n",
       "2                 4                1     0.792453           0.727273   \n",
       "3                 4                1     0.718447           0.421053   \n",
       "4                 2                9     0.475410           0.173913   \n",
       "\n",
       "   avg_shared_trigrams  shared_bigram_pcnt  shared_trigram_pcnt  \\\n",
       "0                    0            0.142857             0.000000   \n",
       "1                    0            0.210526             0.000000   \n",
       "2                    2            0.666667             0.571429   \n",
       "3                    0            0.117647             0.000000   \n",
       "4                    0            0.000000             0.000000   \n",
       "\n",
       "   avg_shared_quadgrams  shared_quadgram_pcnt  \n",
       "0                     0                   0.0  \n",
       "1                     0                   0.0  \n",
       "2                     1                   0.4  \n",
       "3                     0                   0.0  \n",
       "4                     0                   0.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_out.columns = ['nn_out', 'id']\n",
    "nn_out = nn_out.merge(train_features)\n",
    "nn_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sims = pd.read_csv('../roughfeaturedata/train_with_sim_and_ents_long.csv')\n",
    "train_sims = train_sims[['id','similarity_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>nn_out</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>last_char</th>\n",
       "      <th>avg_shared_words</th>\n",
       "      <th>word_count_diff</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>shared_words_pcnt</th>\n",
       "      <th>avg_shared_trigrams</th>\n",
       "      <th>shared_bigram_pcnt</th>\n",
       "      <th>shared_trigram_pcnt</th>\n",
       "      <th>avg_shared_quadgrams</th>\n",
       "      <th>shared_quadgram_pcnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.986684</td>\n",
       "      <td>0.419988</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>9</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.043146</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.647482</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.078106</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.730742</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.846616</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.365217</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  similarity_score    nn_out  \\\n",
       "0   0          0.986684  0.419988   \n",
       "1   1          0.925000  0.043146   \n",
       "2   2          0.929068  0.078106   \n",
       "3   3          0.730742  0.002271   \n",
       "4   4          0.846616  0.003942   \n",
       "\n",
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  last_char  \\\n",
       "0  What is the step by step guide to invest in sh...             0          1   \n",
       "1  What would happen if the Indian government sto...             0          1   \n",
       "2  How can Internet speed be increased by hacking...             0          1   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0          1   \n",
       "4            Which fish would survive in salt water?             0          1   \n",
       "\n",
       "   avg_shared_words  word_count_diff  levenshtein  shared_words_pcnt  \\\n",
       "0                12                2     0.926829           0.923077   \n",
       "1                 4                5     0.647482           0.380952   \n",
       "2                 4                4     0.454545           0.333333   \n",
       "3                 0                2     0.069565           0.000000   \n",
       "4                 2                6     0.365217           0.200000   \n",
       "\n",
       "   avg_shared_trigrams  shared_bigram_pcnt  shared_trigram_pcnt  \\\n",
       "0                    9            0.833333             0.818182   \n",
       "1                    0            0.105263             0.000000   \n",
       "2                    0            0.090909             0.000000   \n",
       "3                    0            0.000000             0.000000   \n",
       "4                    0            0.000000             0.000000   \n",
       "\n",
       "   avg_shared_quadgrams  shared_quadgram_pcnt  \n",
       "0                     8                   0.8  \n",
       "1                     0                   0.0  \n",
       "2                     0                   0.0  \n",
       "3                     0                   0.0  \n",
       "4                     0                   0.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = train_sims.merge(nn_out)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add tfidf and LDA\n",
    "\n",
    "tfidf = pd.read_csv('../data/tfidf_train_features.csv')\n",
    "tfidf = tfidf[['id','tfidf_word_match_share']]\n",
    "tfidf.columns = ['id', 'tfidf_word_match_share']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_modelling = pd.read_csv('../roughfeaturedata/topic_modelling_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = merged.merge(tfidf)\n",
    "merged = merged.merge(topic_modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop nan\n",
    "merged = merged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_features = list(topic_modelling.columns)\n",
    "\n",
    "feature_list = feature_list + topic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>nn_out</th>\n",
       "      <th>last_char</th>\n",
       "      <th>avg_shared_words</th>\n",
       "      <th>word_count_diff</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>shared_words_pcnt</th>\n",
       "      <th>avg_shared_trigrams</th>\n",
       "      <th>shared_bigram_pcnt</th>\n",
       "      <th>shared_trigram_pcnt</th>\n",
       "      <th>...</th>\n",
       "      <th>dissimilarity_topic40</th>\n",
       "      <th>dissimilarity_topic41</th>\n",
       "      <th>dissimilarity_topic42</th>\n",
       "      <th>dissimilarity_topic43</th>\n",
       "      <th>dissimilarity_topic44</th>\n",
       "      <th>dissimilarity_topic45</th>\n",
       "      <th>dissimilarity_topic46</th>\n",
       "      <th>dissimilarity_topic47</th>\n",
       "      <th>dissimilarity_topic48</th>\n",
       "      <th>dissimilarity_topic49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.986684</td>\n",
       "      <td>0.419988</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>9</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.043146</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.647482</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.078106</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.730742</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.846616</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.365217</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   similarity_score    nn_out  last_char  avg_shared_words  word_count_diff  \\\n",
       "0          0.986684  0.419988          1                12                2   \n",
       "1          0.925000  0.043146          1                 4                5   \n",
       "2          0.929068  0.078106          1                 4                4   \n",
       "3          0.730742  0.002271          1                 0                2   \n",
       "4          0.846616  0.003942          1                 2                6   \n",
       "\n",
       "   levenshtein  shared_words_pcnt  avg_shared_trigrams  shared_bigram_pcnt  \\\n",
       "0     0.926829           0.923077                    9            0.833333   \n",
       "1     0.647482           0.380952                    0            0.105263   \n",
       "2     0.454545           0.333333                    0            0.090909   \n",
       "3     0.069565           0.000000                    0            0.000000   \n",
       "4     0.365217           0.200000                    0            0.000000   \n",
       "\n",
       "   shared_trigram_pcnt          ...            dissimilarity_topic40  \\\n",
       "0             0.818182          ...                              0.0   \n",
       "1             0.000000          ...                              0.0   \n",
       "2             0.000000          ...                              0.0   \n",
       "3             0.000000          ...                              0.0   \n",
       "4             0.000000          ...                              0.0   \n",
       "\n",
       "   dissimilarity_topic41  dissimilarity_topic42  dissimilarity_topic43  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "3                    0.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "\n",
       "   dissimilarity_topic44  dissimilarity_topic45  dissimilarity_topic46  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "3                    0.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "\n",
       "   dissimilarity_topic47  dissimilarity_topic48  dissimilarity_topic49  \n",
       "0                    0.0                    0.0                    0.0  \n",
       "1                    0.0                    0.0                    0.0  \n",
       "2                    0.0                    0.0                    0.0  \n",
       "3                    0.0                    0.0                    0.0  \n",
       "4                    0.0                    0.0                    0.0  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = merged['is_duplicate']\n",
    "x = merged[feature_list]\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.247165\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           is_duplicate   No. Observations:               305644\n",
      "Model:                          Logit   Df Residuals:                   305530\n",
      "Method:                           MLE   Df Model:                          113\n",
      "Date:                Wed, 29 Nov 2017   Pseudo R-squ.:                  0.6250\n",
      "Time:                        19:06:57   Log-Likelihood:                -75544.\n",
      "converged:                       True   LL-Null:                   -2.0145e+05\n",
      "                                        LLR p-value:                     0.000\n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "similarity_score          -3.2582      0.054    -60.159      0.000      -3.364      -3.152\n",
      "nn_out                     7.8841      0.029    268.531      0.000       7.827       7.942\n",
      "last_char                 -2.3712      0.042    -56.859      0.000      -2.453      -2.289\n",
      "avg_shared_words           0.0274      0.007      4.188      0.000       0.015       0.040\n",
      "word_count_diff           -0.0033      0.002     -1.421      0.155      -0.008       0.001\n",
      "levenshtein               -0.1730      0.074     -2.342      0.019      -0.318      -0.028\n",
      "shared_words_pcnt          0.8092      0.104      7.797      0.000       0.606       1.013\n",
      "avg_shared_trigrams        0.4109      0.030     13.520      0.000       0.351       0.470\n",
      "shared_bigram_pcnt        -0.4036      0.110     -3.669      0.000      -0.619      -0.188\n",
      "shared_trigram_pcnt       -2.4390      0.208    -11.722      0.000      -2.847      -2.031\n",
      "avg_shared_quadgrams      -0.4007      0.029    -13.893      0.000      -0.457      -0.344\n",
      "shared_quadgram_pcnt       1.0449      0.170      6.156      0.000       0.712       1.378\n",
      "tfidf_word_match_share     1.3827      0.029     47.186      0.000       1.325       1.440\n",
      "id                     -5.986e-07   5.67e-08    -10.560      0.000    -7.1e-07   -4.87e-07\n",
      "similarity_topic0          0.0136      0.128      0.106      0.915      -0.238       0.265\n",
      "similarity_topic1         -0.1426      0.082     -1.747      0.081      -0.303       0.017\n",
      "similarity_topic2         -0.0921      0.116     -0.796      0.426      -0.319       0.135\n",
      "similarity_topic3         -0.1238      0.112     -1.102      0.270      -0.344       0.096\n",
      "similarity_topic4         -0.2532      0.107     -2.356      0.018      -0.464      -0.043\n",
      "similarity_topic5         -0.2713      0.097     -2.791      0.005      -0.462      -0.081\n",
      "similarity_topic6         -0.2100      0.106     -1.979      0.048      -0.418      -0.002\n",
      "similarity_topic7          0.0888      0.124      0.716      0.474      -0.154       0.332\n",
      "similarity_topic8         -0.3758      0.088     -4.281      0.000      -0.548      -0.204\n",
      "similarity_topic9          0.3593      0.127      2.838      0.005       0.111       0.607\n",
      "similarity_topic10         0.1444      0.097      1.493      0.135      -0.045       0.334\n",
      "similarity_topic11        -0.2482      0.083     -2.998      0.003      -0.411      -0.086\n",
      "similarity_topic12        -0.2667      0.137     -1.953      0.051      -0.534       0.001\n",
      "similarity_topic13        -0.1781      0.088     -2.035      0.042      -0.350      -0.007\n",
      "similarity_topic14         0.0188      0.104      0.181      0.856      -0.185       0.223\n",
      "similarity_topic15        -0.0763      0.094     -0.809      0.419      -0.261       0.109\n",
      "similarity_topic16         0.0639      0.102      0.628      0.530      -0.136       0.263\n",
      "similarity_topic17        -0.1574      0.101     -1.556      0.120      -0.356       0.041\n",
      "similarity_topic18         0.4245      0.120      3.527      0.000       0.189       0.660\n",
      "similarity_topic19         0.0920      0.117      0.784      0.433      -0.138       0.322\n",
      "similarity_topic20        -0.1429      0.117     -1.227      0.220      -0.371       0.085\n",
      "similarity_topic21        -0.3024      0.068     -4.421      0.000      -0.436      -0.168\n",
      "similarity_topic22        -0.0710      0.106     -0.670      0.503      -0.279       0.137\n",
      "similarity_topic23         0.1201      0.116      1.036      0.300      -0.107       0.347\n",
      "similarity_topic24        -0.2065      0.097     -2.122      0.034      -0.397      -0.016\n",
      "similarity_topic25        -0.1007      0.066     -1.517      0.129      -0.231       0.029\n",
      "similarity_topic26        -0.1378      0.108     -1.270      0.204      -0.350       0.075\n",
      "similarity_topic27         0.1969      0.132      1.487      0.137      -0.063       0.456\n",
      "similarity_topic28        -0.0967      0.121     -0.802      0.422      -0.333       0.140\n",
      "similarity_topic29         0.0010      0.119      0.008      0.993      -0.232       0.234\n",
      "similarity_topic30        -0.1952      0.112     -1.749      0.080      -0.414       0.023\n",
      "similarity_topic31        -0.1077      0.102     -1.055      0.291      -0.308       0.092\n",
      "similarity_topic32        -0.0878      0.110     -0.800      0.424      -0.303       0.127\n",
      "similarity_topic33        -0.2796      0.102     -2.734      0.006      -0.480      -0.079\n",
      "similarity_topic34        -0.3108      0.071     -4.356      0.000      -0.451      -0.171\n",
      "similarity_topic35        -0.4826      0.072     -6.739      0.000      -0.623      -0.342\n",
      "similarity_topic36        -0.1730      0.103     -1.677      0.094      -0.375       0.029\n",
      "similarity_topic37         0.0034      0.106      0.032      0.974      -0.204       0.210\n",
      "similarity_topic38        -0.1769      0.057     -3.077      0.002      -0.290      -0.064\n",
      "similarity_topic39        -0.1906      0.103     -1.844      0.065      -0.393       0.012\n",
      "similarity_topic40         0.0998      0.111      0.897      0.370      -0.118       0.318\n",
      "similarity_topic41        -0.2632      0.118     -2.224      0.026      -0.495      -0.031\n",
      "similarity_topic42        -0.0720      0.104     -0.692      0.489      -0.276       0.132\n",
      "similarity_topic43         0.2192      0.108      2.035      0.042       0.008       0.430\n",
      "similarity_topic44         0.1779      0.112      1.590      0.112      -0.041       0.397\n",
      "similarity_topic45         0.0319      0.112      0.285      0.776      -0.188       0.252\n",
      "similarity_topic46        -0.0071      0.096     -0.074      0.941      -0.196       0.181\n",
      "similarity_topic47        -0.0421      0.096     -0.438      0.662      -0.230       0.146\n",
      "similarity_topic48        -0.0870      0.123     -0.709      0.478      -0.327       0.153\n",
      "similarity_topic49        -0.0667      0.109     -0.612      0.540      -0.280       0.147\n",
      "dissimilarity_topic0      -0.2504      0.060     -4.171      0.000      -0.368      -0.133\n",
      "dissimilarity_topic1      -0.2062      0.045     -4.556      0.000      -0.295      -0.117\n",
      "dissimilarity_topic2      -0.1412      0.054     -2.599      0.009      -0.248      -0.035\n",
      "dissimilarity_topic3      -0.1427      0.054     -2.654      0.008      -0.248      -0.037\n",
      "dissimilarity_topic4      -0.2103      0.053     -4.005      0.000      -0.313      -0.107\n",
      "dissimilarity_topic5      -0.2132      0.052     -4.138      0.000      -0.314      -0.112\n",
      "dissimilarity_topic6      -0.0971      0.052     -1.855      0.064      -0.200       0.006\n",
      "dissimilarity_topic7      -0.1570      0.055     -2.880      0.004      -0.264      -0.050\n",
      "dissimilarity_topic8      -0.1631      0.056     -2.905      0.004      -0.273      -0.053\n",
      "dissimilarity_topic9      -0.0987      0.063     -1.571      0.116      -0.222       0.024\n",
      "dissimilarity_topic10     -0.1243      0.055     -2.253      0.024      -0.233      -0.016\n",
      "dissimilarity_topic11     -0.1691      0.048     -3.558      0.000      -0.262      -0.076\n",
      "dissimilarity_topic12     -0.2260      0.064     -3.559      0.000      -0.351      -0.102\n",
      "dissimilarity_topic13     -0.2036      0.047     -4.340      0.000      -0.296      -0.112\n",
      "dissimilarity_topic14     -0.1578      0.051     -3.080      0.002      -0.258      -0.057\n",
      "dissimilarity_topic15     -0.2742      0.053     -5.163      0.000      -0.378      -0.170\n",
      "dissimilarity_topic16     -0.0078      0.052     -0.150      0.881      -0.110       0.094\n",
      "dissimilarity_topic17     -0.2677      0.050     -5.408      0.000      -0.365      -0.171\n",
      "dissimilarity_topic18     -0.1659      0.056     -2.941      0.003      -0.277      -0.055\n",
      "dissimilarity_topic19     -0.1528      0.054     -2.838      0.005      -0.258      -0.047\n",
      "dissimilarity_topic20     -0.1783      0.058     -3.055      0.002      -0.293      -0.064\n",
      "dissimilarity_topic21     -0.2095      0.043     -4.819      0.000      -0.295      -0.124\n",
      "dissimilarity_topic22     -0.1383      0.051     -2.702      0.007      -0.239      -0.038\n",
      "dissimilarity_topic23     -0.1759      0.054     -3.251      0.001      -0.282      -0.070\n",
      "dissimilarity_topic24     -0.3018      0.051     -5.911      0.000      -0.402      -0.202\n",
      "dissimilarity_topic25     -0.3219      0.035     -9.070      0.000      -0.391      -0.252\n",
      "dissimilarity_topic26     -0.2684      0.055     -4.874      0.000      -0.376      -0.160\n",
      "dissimilarity_topic27     -0.2119      0.062     -3.433      0.001      -0.333      -0.091\n",
      "dissimilarity_topic28     -0.1102      0.055     -2.016      0.044      -0.217      -0.003\n",
      "dissimilarity_topic29     -0.2966      0.056     -5.291      0.000      -0.406      -0.187\n",
      "dissimilarity_topic30     -0.2102      0.056     -3.753      0.000      -0.320      -0.100\n",
      "dissimilarity_topic31     -0.1210      0.050     -2.418      0.016      -0.219      -0.023\n",
      "dissimilarity_topic32     -0.1204      0.053     -2.287      0.022      -0.224      -0.017\n",
      "dissimilarity_topic33     -0.2217      0.050     -4.477      0.000      -0.319      -0.125\n",
      "dissimilarity_topic34     -0.3488      0.048     -7.282      0.000      -0.443      -0.255\n",
      "dissimilarity_topic35     -0.2105      0.051     -4.125      0.000      -0.311      -0.110\n",
      "dissimilarity_topic36     -0.2311      0.050     -4.658      0.000      -0.328      -0.134\n",
      "dissimilarity_topic37     -0.1765      0.053     -3.328      0.001      -0.280      -0.073\n",
      "dissimilarity_topic38     -0.1170      0.047     -2.488      0.013      -0.209      -0.025\n",
      "dissimilarity_topic39     -0.1941      0.056     -3.490      0.000      -0.303      -0.085\n",
      "dissimilarity_topic40     -0.2585      0.052     -4.938      0.000      -0.361      -0.156\n",
      "dissimilarity_topic41     -0.2319      0.057     -4.097      0.000      -0.343      -0.121\n",
      "dissimilarity_topic42     -0.2793      0.052     -5.406      0.000      -0.381      -0.178\n",
      "dissimilarity_topic43     -0.1275      0.053     -2.391      0.017      -0.232      -0.023\n",
      "dissimilarity_topic44     -0.0920      0.057     -1.604      0.109      -0.204       0.020\n",
      "dissimilarity_topic45     -0.1515      0.054     -2.795      0.005      -0.258      -0.045\n",
      "dissimilarity_topic46     -0.0918      0.055     -1.667      0.095      -0.200       0.016\n",
      "dissimilarity_topic47     -0.1619      0.053     -3.057      0.002      -0.266      -0.058\n",
      "dissimilarity_topic48     -0.1575      0.055     -2.868      0.004      -0.265      -0.050\n",
      "dissimilarity_topic49     -0.1950      0.056     -3.498      0.000      -0.304      -0.086\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logit_model=sm.Logit(y,x)\n",
    "result=logit_model.fit()\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_out_test = pd.read_csv('../roughfeaturedata/test_preds_for_logreg.csv')\n",
    "test_features = pd.read_csv('../data/test_features.csv')\n",
    "tfidf_test_features = pd.read_csv('../data/tfidf_test_features.csv')\n",
    "nn_out_test.columns = ['nn_out','test_id']\n",
    "nn_out_test = nn_out_test.merge(test_features)\n",
    "nn_out_test = nn_out_test.merge(tfidf_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modelling.columns = ['test_id'] + topic_features[1:]\n",
    "nn_out_test = nn_out_test.merge(topic_modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nn_out</th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>last_char</th>\n",
       "      <th>avg_shared_words</th>\n",
       "      <th>word_count_diff</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>shared_words_pcnt</th>\n",
       "      <th>avg_shared_trigrams</th>\n",
       "      <th>...</th>\n",
       "      <th>dissimilarity_topic40</th>\n",
       "      <th>dissimilarity_topic41</th>\n",
       "      <th>dissimilarity_topic42</th>\n",
       "      <th>dissimilarity_topic43</th>\n",
       "      <th>dissimilarity_topic44</th>\n",
       "      <th>dissimilarity_topic45</th>\n",
       "      <th>dissimilarity_topic46</th>\n",
       "      <th>dissimilarity_topic47</th>\n",
       "      <th>dissimilarity_topic48</th>\n",
       "      <th>dissimilarity_topic49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998650</td>\n",
       "      <td>15</td>\n",
       "      <td>What would a Trump presidency mean for current...</td>\n",
       "      <td>How will a Trump presidency affect the student...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.637905</td>\n",
       "      <td>20</td>\n",
       "      <td>Why do rockets look white?</td>\n",
       "      <td>Why are rockets and boosters painted white?</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075683</td>\n",
       "      <td>21</td>\n",
       "      <td>What's causing someone to be jealous?</td>\n",
       "      <td>What can I do to avoid being jealous of someone?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002341</td>\n",
       "      <td>23</td>\n",
       "      <td>How much is 30 kV in HP?</td>\n",
       "      <td>Where can I find a conversion chart for CC to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.099990</td>\n",
       "      <td>34</td>\n",
       "      <td>What is the best travel website in spain?</td>\n",
       "      <td>What is the best travel website?</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     nn_out  test_id                                          question1  \\\n",
       "0  0.998650       15  What would a Trump presidency mean for current...   \n",
       "1  0.637905       20                         Why do rockets look white?   \n",
       "2  0.075683       21              What's causing someone to be jealous?   \n",
       "3  0.002341       23                           How much is 30 kV in HP?   \n",
       "4  0.099990       34          What is the best travel website in spain?   \n",
       "\n",
       "                                           question2  last_char  \\\n",
       "0  How will a Trump presidency affect the student...          1   \n",
       "1        Why are rockets and boosters painted white?          1   \n",
       "2   What can I do to avoid being jealous of someone?          1   \n",
       "3  Where can I find a conversion chart for CC to ...          1   \n",
       "4                   What is the best travel website?          1   \n",
       "\n",
       "   avg_shared_words  word_count_diff  levenshtein  shared_words_pcnt  \\\n",
       "0                 4                2     0.505376           0.250000   \n",
       "1                 3                2     0.637681           0.500000   \n",
       "2                 1                4     0.447059           0.125000   \n",
       "3                 0                4     0.074074           0.000000   \n",
       "4                 5                2     0.876712           0.714286   \n",
       "\n",
       "   avg_shared_trigrams          ...            dissimilarity_topic40  \\\n",
       "0                    1          ...                              0.0   \n",
       "1                    0          ...                              0.0   \n",
       "2                    0          ...                              0.0   \n",
       "3                    0          ...                              0.0   \n",
       "4                    3          ...                              0.0   \n",
       "\n",
       "   dissimilarity_topic41  dissimilarity_topic42  dissimilarity_topic43  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "3                    0.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "\n",
       "   dissimilarity_topic44  dissimilarity_topic45  dissimilarity_topic46  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "3                    1.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "\n",
       "   dissimilarity_topic47  dissimilarity_topic48  dissimilarity_topic49  \n",
       "0                    0.0                    0.0                    0.0  \n",
       "1                    0.0                    0.0                    0.0  \n",
       "2                    0.0                    0.0                    0.0  \n",
       "3                    0.0                    0.0                    0.0  \n",
       "4                    0.0                    0.0                    0.0  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../roughfeaturedata/test_with_sim_and_ents_long.csv')\n",
    "test = test[['test_id','similarity_score']]\n",
    "test_merged = test.merge(nn_out_test)\n",
    "nn_out_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list.remove('test_id')\n",
    "x_test = test_merged[feature_list]\n",
    "x_test = x_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(x, y)\n",
    "y_pred = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = pd.DataFrame({\"test_id\":test_merged['test_id'], \"is_duplicate\":y_pred})\n",
    "predict.to_csv(\"logregattempt7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>test_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_duplicate  test_id\n",
       "0             1       15\n",
       "1             1       20\n",
       "2             0       21\n",
       "3             0       23\n",
       "4             0       34"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
