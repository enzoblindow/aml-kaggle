{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(49)\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import codecs\n",
    "import random\n",
    "import keras\n",
    "import sys\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Dropout, Embedding\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Read in train\n",
    "###APPEND LABELS TO TRAINING DATA \n",
    "\n",
    "df_train = pd.read_csv('data/train_data.csv')\n",
    "df_train.drop(['is_duplicate'], axis= 1, inplace = True)\n",
    "df_labels = pd.read_csv('data/train_labels.csv')\n",
    "df_train = df_train.merge(df_labels)\n",
    "\n",
    "###Read in test\n",
    "\n",
    "test = pd.read_csv('data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Create train and Cros-validation sets\n",
    "#train, CV = train_test_split(df_train, train_size = 0.8, random_state = 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Transform into series\n",
    "###Train\n",
    "train_qs_1 = pd.Series(df_train['question1']) \n",
    "train_qs_2 = pd.Series(df_train['question2']) \n",
    "labels = pd.Series(df_train['is_duplicate'])\n",
    "train_ids = pd.Series(df_train['id'])\n",
    "\n",
    "###Test\n",
    "test_qs_1 = pd.Series(test['question1']) \n",
    "test_qs_2 = pd.Series(test['question2']) \n",
    "test_ids = pd.Series(test['test_id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create full lists for text processing:\n",
    "\n",
    "all_texts = train_qs_1.astype(str).tolist() + train_qs_2.astype(str).tolist() + test_qs_1.astype(str).tolist() + test_qs_1.astype(str).tolist()\n",
    "\n",
    "train_q1 = train_qs_1.astype(str).tolist()\n",
    "train_q2 = train_qs_2.astype(str).tolist()\n",
    "\n",
    "test_q1 = test_qs_1.astype(str).tolist()\n",
    "test_q2 = test_qs_2.astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create word index from Glove\n",
    "embeddings_index = {}\n",
    "glove_path = '/Users/tom/Msc Data Science/Machine Learning/Assignments/Quora/Glove.6B/glove.6B.300d.txt'\n",
    "glove = codecs.open(glove_path, encoding='utf-8')\n",
    "\n",
    "for row in glove:\n",
    "    word_dims = row.split(' ')\n",
    "    index = word_dims[0]\n",
    "    dims = np.asarray(word_dims[1:], dtype='float32')\n",
    "    embeddings_index[index] = dims\n",
    "    \n",
    "glove.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tokenize all uing Keras Tokenizer\n",
    "\n",
    "##Fit tokenizer:\n",
    "max_tok_words = 100000\n",
    "tokenizer = Tokenizer(num_words=max_tok_words)\n",
    "tokenizer.fit_on_texts(all_texts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "#Create sequences to tokenize\n",
    "\n",
    "train_seq_1 = tokenizer.texts_to_sequences(train_q1)\n",
    "train_seq_2 = tokenizer.texts_to_sequences(train_q2)\n",
    "\n",
    "test_seq_1 = tokenizer.texts_to_sequences(test_q1)\n",
    "test_seq_2 = tokenizer.texts_to_sequences(test_q2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify appropriate padding length:\n",
    "full_seq = train_seq_1 + train_seq_2 + test_seq_1 + test_seq_2\n",
    "#99.5th percentile\n",
    "max_pad_len = int(np.percentile([len(x) for x in full_seq],99.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply padding:\n",
    "\n",
    "padded_train_1 = pad_sequences(train_seq_1, maxlen=max_pad_len)\n",
    "padded_train_2 = pad_sequences(train_seq_2, maxlen=max_pad_len)\n",
    "\n",
    "padded_test_1 = pad_sequences(test_seq_1, maxlen=max_pad_len)\n",
    "padded_test_2 = pad_sequences(test_seq_2, maxlen=max_pad_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create word embeddings\n",
    "\n",
    "index_length = len(word_index)\n",
    "embedding_matrix = np.zeros((index_length+1, 300))\n",
    "\n",
    "\n",
    "for w, i in word_index.items():\n",
    "    \n",
    "    #if i >= index_length:\n",
    "    if i > index_length:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(w)\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Optional: Augment data to contain Q2 vs Q1 swapped - effectively doubling training data\n",
    "\n",
    "# padded_train_1 = np.concatenate([padded_train_1,padded_train_2], axis = 0)\n",
    "# padded_train_2 = np.concatenate([padded_train_2,padded_train_1], axis = 0)\n",
    "# labels = np.concatenate([labels,labels], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Embedding layer for LSTM\n",
    "embedding_layer = Embedding(index_length+1,300,weights=[embedding_matrix],input_length=max_pad_len)\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "lstm_nodes = [200,300,400]\n",
    "dense_nodes = [100,200,300]\n",
    "\n",
    "lstm_drop = [0.1,0.15,0.2,0.25,0.3]\n",
    "dense_drop = [0.1,0.15,0.2,0.25,0.3]\n",
    "\n",
    "dense_activation = ['relu','sigmoid']\n",
    "\n",
    "lstm_bidirectional = [True,False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random initialization\n",
    "\n",
    "lstm_nodes_choice = 300 #random.choice(lstm_nodes)\n",
    "dense_nodes_choice = 200 #random.choice(dense_nodes)\n",
    "\n",
    "lstm_drop_choice = 0.2 #random.choice(lstm_drop)\n",
    "dense_drop_choice = 0.2 #random.choice(dense_drop)\n",
    "\n",
    "dense_activation_choice = 'relu' #random.choice(dense_activation)\n",
    "\n",
    "lstm_bidirectional_choice = True #random.choice(lstm_bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build LSTM layer (Bidirectional if picked)\n",
    "if lstm_bidirectional_choice:    \n",
    "    lstm_layer = Bidirectional(LSTM(lstm_nodes_choice, dropout=lstm_drop_choice, recurrent_dropout=lstm_drop_choice))\n",
    "else:\n",
    "    lstm_layer = LSTM(lstm_nodes_choice, dropout=lstm_drop_choice, recurrent_dropout=lstm_drop_choice)\n",
    "\n",
    "#Question 1 input layer\n",
    "input_1 = Input(shape=(max_pad_len,), dtype='int32')\n",
    "embedded_1 = embedding_layer(input_1)\n",
    "q1 = lstm_layer(embedded_1)\n",
    "\n",
    "#Question 2 input layer\n",
    "input_2 = Input(shape=(max_pad_len,), dtype='int32')\n",
    "embedded_2 = embedding_layer(input_2)\n",
    "q2 = lstm_layer(embedded_2)\n",
    "\n",
    "#Combine outputs from q1 and q2\n",
    "combined_layer = concatenate([q1, q2])\n",
    "combined_layer = Dropout(lstm_drop_choice)(combined_layer)\n",
    "combined_layer = BatchNormalization()(combined_layer)\n",
    "\n",
    "#First Dense layer\n",
    "combined_layer = Dense(dense_nodes_choice, activation=dense_activation_choice)(combined_layer)\n",
    "combined_layer = Dropout(dense_drop_choice)(combined_layer)\n",
    "combined_layer = BatchNormalization()(combined_layer)\n",
    "\n",
    "#Second Dense layer\n",
    "combined_layer = Dense(dense_nodes_choice, activation=dense_activation_choice)(combined_layer)\n",
    "combined_layer = Dropout(dense_drop_choice)(combined_layer)\n",
    "combined_layer = BatchNormalization()(combined_layer)\n",
    "\n",
    "#Prediction Dense Layer\n",
    "prediction_layer = Dense(1, activation='sigmoid')(combined_layer)\n",
    "\n",
    "#Compile Model\n",
    "model = Model(inputs=[input_1, input_2],outputs=prediction_layer)\n",
    "model.compile(loss='binary_crossentropy',optimizer='nadam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 258531 samples, validate on 64633 samples\n",
      "Epoch 1/5\n",
      "258531/258531 [==============================] - 6157s - loss: 0.3396 - acc: 0.8429 - val_loss: 0.5657 - val_acc: 0.7172\n",
      "Epoch 2/5\n",
      "258531/258531 [==============================] - 5630s - loss: 0.2162 - acc: 0.9050 - val_loss: 0.6046 - val_acc: 0.7983\n",
      "Epoch 3/5\n",
      "258531/258531 [==============================] - 5540s - loss: 0.1817 - acc: 0.9229 - val_loss: 0.5878 - val_acc: 0.8113\n",
      "Epoch 4/5\n",
      "258531/258531 [==============================] - 5839s - loss: 0.1621 - acc: 0.9315 - val_loss: 0.6649 - val_acc: 0.8035\n",
      "Epoch 5/5\n",
      "258531/258531 [==============================] - 5812s - loss: 0.1471 - acc: 0.9382 - val_loss: 0.6807 - val_acc: 0.8147\n"
     ]
    }
   ],
   "source": [
    "#Fit Model\n",
    "epochs = 5\n",
    "logging = model.fit([padded_train_1,padded_train_2], labels , validation_split = 0.2, epochs=epochs, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_lstm = [lstm_nodes_choice] * epochs\n",
    "nodes_dense = [dense_nodes_choice] * epochs\n",
    "\n",
    "drop_lstm = [lstm_drop_choice] * epochs\n",
    "drop_dense = [dense_drop_choice] * epochs\n",
    "\n",
    "activation_dense = [dense_activation_choice] * epochs\n",
    "\n",
    "lstm_bidirectional = [lstm_bidirectional_choice] * epochs\n",
    "\n",
    "epoch_cnt = range(1,epochs+1)\n",
    "\n",
    "acc = logging.history['acc']\n",
    "val_acc = logging.history['val_acc']\n",
    "loss = logging.history['loss']\n",
    "val_loss = logging.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame(\n",
    "    {'nodes_lstm': nodes_lstm,\n",
    "    'nodes_dense': nodes_dense,\n",
    "    'drop_lstm': drop_lstm,\n",
    "    'drop_dense': drop_dense,\n",
    "    'activation_dense': activation_dense,\n",
    "    'lstm_bidirectional': lstm_bidirectional,\n",
    "    'epoch_cnt': epoch_cnt,\n",
    "    'acc': acc,\n",
    "    'val_acc': val_acc,\n",
    "    'loss': loss,\n",
    "    'val_loss': val_loss\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master.append(performance,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master.to_csv(\"performance_out.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict([padded_test_1, padded_test_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({\"test_id\":test_ids, \"nn_out\":test_predictions.ravel()})\n",
    "#test_df.to_csv(\"test_preds_for_logreg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict([padded_train_1,padded_train_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({\"test_id\":train_ids, \"nn_out\":train_predictions.ravel()})\n",
    "#train_df.to_csv(\"preds_for_logreg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>activation_dense</th>\n",
       "      <th>drop_dense</th>\n",
       "      <th>drop_lstm</th>\n",
       "      <th>epoch_cnt</th>\n",
       "      <th>loss</th>\n",
       "      <th>lstm_bidirectional</th>\n",
       "      <th>nodes_dense</th>\n",
       "      <th>nodes_lstm</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.752150</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506772</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.780097</td>\n",
       "      <td>0.463245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.803424</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.416057</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.796822</td>\n",
       "      <td>0.426125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.837749</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.353868</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.801556</td>\n",
       "      <td>0.423007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.865351</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.300552</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.806028</td>\n",
       "      <td>0.439879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.885840</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259767</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.818081</td>\n",
       "      <td>0.456929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.823685</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.376889</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>0.765012</td>\n",
       "      <td>0.471562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.882355</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.264482</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>0.805053</td>\n",
       "      <td>0.465731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.900882</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.226010</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>0.813021</td>\n",
       "      <td>0.492255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.914088</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.199051</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>0.803939</td>\n",
       "      <td>0.571441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.924245</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.178023</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>0.818730</td>\n",
       "      <td>0.607322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc activation_dense  drop_dense  drop_lstm  epoch_cnt      loss  \\\n",
       "0  0.752150             relu         0.2        0.2          1  0.506772   \n",
       "1  0.803424             relu         0.2        0.2          2  0.416057   \n",
       "2  0.837749             relu         0.2        0.2          3  0.353868   \n",
       "3  0.865351             relu         0.2        0.2          4  0.300552   \n",
       "4  0.885840             relu         0.2        0.2          5  0.259767   \n",
       "5  0.823685             relu         0.2        0.2          1  0.376889   \n",
       "6  0.882355             relu         0.2        0.2          2  0.264482   \n",
       "7  0.900882             relu         0.2        0.2          3  0.226010   \n",
       "8  0.914088             relu         0.2        0.2          4  0.199051   \n",
       "9  0.924245             relu         0.2        0.2          5  0.178023   \n",
       "\n",
       "   lstm_bidirectional  nodes_dense  nodes_lstm   val_acc  val_loss  \n",
       "0               False          200         300  0.780097  0.463245  \n",
       "1               False          200         300  0.796822  0.426125  \n",
       "2               False          200         300  0.801556  0.423007  \n",
       "3               False          200         300  0.806028  0.439879  \n",
       "4               False          200         300  0.818081  0.456929  \n",
       "5               False          300         400  0.765012  0.471562  \n",
       "6               False          300         400  0.805053  0.465731  \n",
       "7               False          300         400  0.813021  0.492255  \n",
       "8               False          300         400  0.803939  0.571441  \n",
       "9               False          300         400  0.818730  0.607322  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>activation_dense</th>\n",
       "      <th>drop_dense</th>\n",
       "      <th>drop_lstm</th>\n",
       "      <th>epoch_cnt</th>\n",
       "      <th>loss</th>\n",
       "      <th>lstm_bidirectional</th>\n",
       "      <th>nodes_dense</th>\n",
       "      <th>nodes_lstm</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.752150</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506772</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.780097</td>\n",
       "      <td>0.463245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.803424</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.416057</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.796822</td>\n",
       "      <td>0.426125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.837749</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.353868</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.801556</td>\n",
       "      <td>0.423007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.865351</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.300552</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.806028</td>\n",
       "      <td>0.439879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.885840</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259767</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.818081</td>\n",
       "      <td>0.456929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.823685</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.376889</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>0.765012</td>\n",
       "      <td>0.471562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.882355</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.264482</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>0.805053</td>\n",
       "      <td>0.465731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.900882</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.226010</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>0.813021</td>\n",
       "      <td>0.492255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.914088</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.199051</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>0.803939</td>\n",
       "      <td>0.571441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.924245</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.178023</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>0.818730</td>\n",
       "      <td>0.607322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.842851</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.339586</td>\n",
       "      <td>True</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.717234</td>\n",
       "      <td>0.565672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.904990</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.216202</td>\n",
       "      <td>True</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.798276</td>\n",
       "      <td>0.604551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.922884</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.181705</td>\n",
       "      <td>True</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.811273</td>\n",
       "      <td>0.587753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.931501</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>True</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.803490</td>\n",
       "      <td>0.664947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.938247</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.147051</td>\n",
       "      <td>True</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>0.814661</td>\n",
       "      <td>0.680679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acc activation_dense  drop_dense  drop_lstm  epoch_cnt      loss  \\\n",
       "0   0.752150             relu         0.2        0.2          1  0.506772   \n",
       "1   0.803424             relu         0.2        0.2          2  0.416057   \n",
       "2   0.837749             relu         0.2        0.2          3  0.353868   \n",
       "3   0.865351             relu         0.2        0.2          4  0.300552   \n",
       "4   0.885840             relu         0.2        0.2          5  0.259767   \n",
       "5   0.823685             relu         0.2        0.2          1  0.376889   \n",
       "6   0.882355             relu         0.2        0.2          2  0.264482   \n",
       "7   0.900882             relu         0.2        0.2          3  0.226010   \n",
       "8   0.914088             relu         0.2        0.2          4  0.199051   \n",
       "9   0.924245             relu         0.2        0.2          5  0.178023   \n",
       "10  0.842851             relu         0.2        0.2          1  0.339586   \n",
       "11  0.904990             relu         0.2        0.2          2  0.216202   \n",
       "12  0.922884             relu         0.2        0.2          3  0.181705   \n",
       "13  0.931501             relu         0.2        0.2          4  0.162071   \n",
       "14  0.938247             relu         0.2        0.2          5  0.147051   \n",
       "\n",
       "    lstm_bidirectional  nodes_dense  nodes_lstm   val_acc  val_loss  \n",
       "0                False          200         300  0.780097  0.463245  \n",
       "1                False          200         300  0.796822  0.426125  \n",
       "2                False          200         300  0.801556  0.423007  \n",
       "3                False          200         300  0.806028  0.439879  \n",
       "4                False          200         300  0.818081  0.456929  \n",
       "5                False          300         400  0.765012  0.471562  \n",
       "6                False          300         400  0.805053  0.465731  \n",
       "7                False          300         400  0.813021  0.492255  \n",
       "8                False          300         400  0.803939  0.571441  \n",
       "9                False          300         400  0.818730  0.607322  \n",
       "10                True          200         300  0.717234  0.565672  \n",
       "11                True          200         300  0.798276  0.604551  \n",
       "12                True          200         300  0.811273  0.587753  \n",
       "13                True          200         300  0.803490  0.664947  \n",
       "14                True          200         300  0.814661  0.680679  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master.to_csv(\"performance_out.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
