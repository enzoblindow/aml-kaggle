{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training\n",
    "nn_out = pd.read_csv('roughfeaturedata/preds_for_logreg.csv')\n",
    "train_features = pd.read_csv('data/train_features.csv')\n",
    "train_sims = pd.read_csv('roughfeaturedata/train_with_sim_and_ents_long.csv')\n",
    "tfidf_train_features = pd.read_csv('data/tfidf_train_features.csv')\n",
    "topic_modelling_train = pd.read_csv('roughfeaturedata/topic_modelling_output.csv')\n",
    "\n",
    "#test\n",
    "nn_out_test = pd.read_csv('roughfeaturedata/test_preds_for_logreg.csv')\n",
    "test_features = pd.read_csv('data/test_features.csv')\n",
    "tfidf_test_features = pd.read_csv('data/tfidf_test_features.csv')\n",
    "test_sims = pd.read_csv('roughfeaturedata/test_with_sim_and_ents_long.csv')\n",
    "topic_modelling_test = pd.read_csv('roughfeaturedata/topic_modelling_output.csv')\n",
    "topic_modelling_test.columns = ['test_id'] + list(topic_modelling_test.columns[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Complete Test + Training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build training\n",
    "\n",
    "train = nn_out.merge(train_features, on = 'id')\n",
    "train = train.merge(train_sims, on = 'id')\n",
    "train = train.merge(tfidf_train_features, on = 'id')\n",
    "train = train.merge(topic_modelling_train, on = 'id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build test\n",
    "\n",
    "test = nn_out_test.merge(test_features, on = 'test_id')\n",
    "test = test.merge(test_sims, on = 'test_id')\n",
    "test = test.merge(tfidf_test_features, on = 'test_id')\n",
    "test = test.merge(topic_modelling_test, on = 'test_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature list (comment out to exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featurelist = ['similarity_score',\n",
    "                'nn_out',\n",
    "                'last_char',\n",
    "                'avg_shared_words',\n",
    "                'word_count_diff',\n",
    "                'levenshtein',\n",
    "                'shared_words_pcnt',\n",
    "                'avg_shared_trigrams',\n",
    "                'shared_bigram_pcnt',\n",
    "                'shared_trigram_pcnt',\n",
    "                'avg_shared_quadgrams',\n",
    "                'shared_quadgram_pcnt',\n",
    "                'tfidf_word_match_share'] + list(topic_modelling_test.columns[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "train_x = train[featurelist]\n",
    "train_y = train['is_duplicate']\n",
    "\n",
    "test = test.fillna(0)\n",
    "test_x = test[featurelist]\n",
    "y_labs = test['test_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spot-check regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.246996\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           is_duplicate   No. Observations:               306325\n",
      "Model:                          Logit   Df Residuals:                   306212\n",
      "Method:                           MLE   Df Model:                          112\n",
      "Date:                Wed, 29 Nov 2017   Pseudo R-squ.:                  0.6250\n",
      "Time:                        20:14:59   Log-Likelihood:                -75661.\n",
      "converged:                       True   LL-Null:                   -2.0177e+05\n",
      "                                        LLR p-value:                     0.000\n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "similarity_score          -3.3292      0.053    -62.258      0.000      -3.434      -3.224\n",
      "nn_out                     7.8905      0.029    268.864      0.000       7.833       7.948\n",
      "last_char                 -2.4134      0.041    -58.482      0.000      -2.494      -2.332\n",
      "avg_shared_words           0.0279      0.007      4.285      0.000       0.015       0.041\n",
      "word_count_diff           -0.0050      0.002     -2.098      0.036      -0.010      -0.000\n",
      "levenshtein               -0.2129      0.074     -2.887      0.004      -0.357      -0.068\n",
      "shared_words_pcnt          0.8100      0.104      7.818      0.000       0.607       1.013\n",
      "avg_shared_trigrams        0.4110      0.030     13.545      0.000       0.351       0.470\n",
      "shared_bigram_pcnt        -0.4275      0.110     -3.900      0.000      -0.642      -0.213\n",
      "shared_trigram_pcnt       -2.3864      0.207    -11.518      0.000      -2.793      -1.980\n",
      "avg_shared_quadgrams      -0.4010      0.029    -13.921      0.000      -0.458      -0.345\n",
      "shared_quadgram_pcnt       1.0211      0.169      6.030      0.000       0.689       1.353\n",
      "tfidf_word_match_share     1.3969      0.029     47.822      0.000       1.340       1.454\n",
      "similarity_topic0          0.0130      0.129      0.101      0.919      -0.239       0.265\n",
      "similarity_topic1         -0.1410      0.082     -1.727      0.084      -0.301       0.019\n",
      "similarity_topic2         -0.0860      0.116     -0.744      0.457      -0.313       0.141\n",
      "similarity_topic3         -0.1169      0.112     -1.042      0.298      -0.337       0.103\n",
      "similarity_topic4         -0.2531      0.107     -2.357      0.018      -0.464      -0.043\n",
      "similarity_topic5         -0.2663      0.097     -2.736      0.006      -0.457      -0.076\n",
      "similarity_topic6         -0.2121      0.106     -1.996      0.046      -0.420      -0.004\n",
      "similarity_topic7          0.0889      0.124      0.715      0.475      -0.155       0.333\n",
      "similarity_topic8         -0.3747      0.088     -4.272      0.000      -0.547      -0.203\n",
      "similarity_topic9          0.3647      0.127      2.877      0.004       0.116       0.613\n",
      "similarity_topic10         0.1467      0.097      1.516      0.130      -0.043       0.336\n",
      "similarity_topic11        -0.2426      0.083     -2.926      0.003      -0.405      -0.080\n",
      "similarity_topic12        -0.2716      0.136     -1.990      0.047      -0.539      -0.004\n",
      "similarity_topic13        -0.1761      0.087     -2.013      0.044      -0.348      -0.005\n",
      "similarity_topic14         0.0229      0.104      0.221      0.825      -0.181       0.227\n",
      "similarity_topic15        -0.0743      0.094     -0.787      0.431      -0.259       0.111\n",
      "similarity_topic16         0.0685      0.102      0.673      0.501      -0.131       0.268\n",
      "similarity_topic17        -0.1554      0.101     -1.536      0.124      -0.354       0.043\n",
      "similarity_topic18         0.4309      0.120      3.584      0.000       0.195       0.666\n",
      "similarity_topic19         0.0925      0.117      0.788      0.430      -0.137       0.322\n",
      "similarity_topic20        -0.1401      0.116     -1.203      0.229      -0.368       0.088\n",
      "similarity_topic21        -0.2992      0.068     -4.375      0.000      -0.433      -0.165\n",
      "similarity_topic22        -0.0660      0.106     -0.624      0.533      -0.273       0.141\n",
      "similarity_topic23         0.1244      0.116      1.074      0.283      -0.103       0.351\n",
      "similarity_topic24        -0.2034      0.097     -2.091      0.037      -0.394      -0.013\n",
      "similarity_topic25        -0.0979      0.066     -1.474      0.141      -0.228       0.032\n",
      "similarity_topic26        -0.1297      0.109     -1.195      0.232      -0.342       0.083\n",
      "similarity_topic27         0.2010      0.133      1.516      0.130      -0.059       0.461\n",
      "similarity_topic28        -0.0913      0.121     -0.756      0.450      -0.328       0.145\n",
      "similarity_topic29        -0.0001      0.119     -0.001      0.999      -0.233       0.233\n",
      "similarity_topic30        -0.1915      0.112     -1.716      0.086      -0.410       0.027\n",
      "similarity_topic31        -0.1046      0.102     -1.025      0.305      -0.305       0.095\n",
      "similarity_topic32        -0.0805      0.110     -0.734      0.463      -0.295       0.135\n",
      "similarity_topic33        -0.2820      0.102     -2.760      0.006      -0.482      -0.082\n",
      "similarity_topic34        -0.3081      0.071     -4.319      0.000      -0.448      -0.168\n",
      "similarity_topic35        -0.4823      0.072     -6.740      0.000      -0.623      -0.342\n",
      "similarity_topic36        -0.1694      0.103     -1.642      0.101      -0.372       0.033\n",
      "similarity_topic37         0.0068      0.106      0.064      0.949      -0.200       0.214\n",
      "similarity_topic38        -0.1752      0.057     -3.048      0.002      -0.288      -0.063\n",
      "similarity_topic39        -0.1827      0.103     -1.768      0.077      -0.385       0.020\n",
      "similarity_topic40         0.1056      0.111      0.948      0.343      -0.113       0.324\n",
      "similarity_topic41        -0.2578      0.118     -2.178      0.029      -0.490      -0.026\n",
      "similarity_topic42        -0.0688      0.104     -0.660      0.509      -0.273       0.135\n",
      "similarity_topic43         0.2197      0.108      2.040      0.041       0.009       0.431\n",
      "similarity_topic44         0.1736      0.112      1.552      0.121      -0.046       0.393\n",
      "similarity_topic45         0.0352      0.112      0.314      0.753      -0.184       0.255\n",
      "similarity_topic46        -0.0040      0.096     -0.041      0.967      -0.192       0.185\n",
      "similarity_topic47        -0.0414      0.096     -0.430      0.667      -0.230       0.147\n",
      "similarity_topic48        -0.0791      0.123     -0.645      0.519      -0.320       0.161\n",
      "similarity_topic49        -0.0642      0.109     -0.589      0.556      -0.278       0.150\n",
      "dissimilarity_topic0      -0.2484      0.060     -4.137      0.000      -0.366      -0.131\n",
      "dissimilarity_topic1      -0.2067      0.045     -4.570      0.000      -0.295      -0.118\n",
      "dissimilarity_topic2      -0.1391      0.054     -2.561      0.010      -0.246      -0.033\n",
      "dissimilarity_topic3      -0.1420      0.054     -2.641      0.008      -0.247      -0.037\n",
      "dissimilarity_topic4      -0.2064      0.052     -3.934      0.000      -0.309      -0.104\n",
      "dissimilarity_topic5      -0.2116      0.051     -4.109      0.000      -0.312      -0.111\n",
      "dissimilarity_topic6      -0.0959      0.052     -1.831      0.067      -0.198       0.007\n",
      "dissimilarity_topic7      -0.1539      0.054     -2.823      0.005      -0.261      -0.047\n",
      "dissimilarity_topic8      -0.1630      0.056     -2.905      0.004      -0.273      -0.053\n",
      "dissimilarity_topic9      -0.0983      0.063     -1.565      0.118      -0.221       0.025\n",
      "dissimilarity_topic10     -0.1212      0.055     -2.198      0.028      -0.229      -0.013\n",
      "dissimilarity_topic11     -0.1678      0.048     -3.531      0.000      -0.261      -0.075\n",
      "dissimilarity_topic12     -0.2240      0.063     -3.529      0.000      -0.348      -0.100\n",
      "dissimilarity_topic13     -0.2004      0.047     -4.274      0.000      -0.292      -0.109\n",
      "dissimilarity_topic14     -0.1585      0.051     -3.098      0.002      -0.259      -0.058\n",
      "dissimilarity_topic15     -0.2749      0.053     -5.174      0.000      -0.379      -0.171\n",
      "dissimilarity_topic16     -0.0042      0.052     -0.080      0.936      -0.106       0.098\n",
      "dissimilarity_topic17     -0.2632      0.049     -5.319      0.000      -0.360      -0.166\n",
      "dissimilarity_topic18     -0.1649      0.056     -2.924      0.003      -0.275      -0.054\n",
      "dissimilarity_topic19     -0.1491      0.054     -2.770      0.006      -0.255      -0.044\n",
      "dissimilarity_topic20     -0.1795      0.058     -3.075      0.002      -0.294      -0.065\n",
      "dissimilarity_topic21     -0.2080      0.043     -4.784      0.000      -0.293      -0.123\n",
      "dissimilarity_topic22     -0.1359      0.051     -2.657      0.008      -0.236      -0.036\n",
      "dissimilarity_topic23     -0.1728      0.054     -3.195      0.001      -0.279      -0.067\n",
      "dissimilarity_topic24     -0.3004      0.051     -5.888      0.000      -0.400      -0.200\n",
      "dissimilarity_topic25     -0.3205      0.035     -9.034      0.000      -0.390      -0.251\n",
      "dissimilarity_topic26     -0.2670      0.055     -4.850      0.000      -0.375      -0.159\n",
      "dissimilarity_topic27     -0.2119      0.062     -3.435      0.001      -0.333      -0.091\n",
      "dissimilarity_topic28     -0.1069      0.055     -1.956      0.050      -0.214       0.000\n",
      "dissimilarity_topic29     -0.2981      0.056     -5.321      0.000      -0.408      -0.188\n",
      "dissimilarity_topic30     -0.2081      0.056     -3.719      0.000      -0.318      -0.098\n",
      "dissimilarity_topic31     -0.1219      0.050     -2.436      0.015      -0.220      -0.024\n",
      "dissimilarity_topic32     -0.1195      0.053     -2.270      0.023      -0.223      -0.016\n",
      "dissimilarity_topic33     -0.2215      0.049     -4.476      0.000      -0.319      -0.125\n",
      "dissimilarity_topic34     -0.3486      0.048     -7.278      0.000      -0.443      -0.255\n",
      "dissimilarity_topic35     -0.2085      0.051     -4.087      0.000      -0.308      -0.109\n",
      "dissimilarity_topic36     -0.2306      0.050     -4.650      0.000      -0.328      -0.133\n",
      "dissimilarity_topic37     -0.1760      0.053     -3.320      0.001      -0.280      -0.072\n",
      "dissimilarity_topic38     -0.1153      0.047     -2.453      0.014      -0.207      -0.023\n",
      "dissimilarity_topic39     -0.1944      0.056     -3.498      0.000      -0.303      -0.085\n",
      "dissimilarity_topic40     -0.2586      0.052     -4.943      0.000      -0.361      -0.156\n",
      "dissimilarity_topic41     -0.2303      0.057     -4.071      0.000      -0.341      -0.119\n",
      "dissimilarity_topic42     -0.2782      0.052     -5.386      0.000      -0.379      -0.177\n",
      "dissimilarity_topic43     -0.1277      0.053     -2.397      0.017      -0.232      -0.023\n",
      "dissimilarity_topic44     -0.0916      0.057     -1.598      0.110      -0.204       0.021\n",
      "dissimilarity_topic45     -0.1498      0.054     -2.769      0.006      -0.256      -0.044\n",
      "dissimilarity_topic46     -0.0890      0.055     -1.616      0.106      -0.197       0.019\n",
      "dissimilarity_topic47     -0.1627      0.053     -3.073      0.002      -0.266      -0.059\n",
      "dissimilarity_topic48     -0.1564      0.055     -2.849      0.004      -0.264      -0.049\n",
      "dissimilarity_topic49     -0.1946      0.056     -3.493      0.000      -0.304      -0.085\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_model=sm.Logit(train_y,train_x)\n",
    "result=logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_x, train_y)\n",
    "y_pred = logreg.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\"test_id\":y_labs, \"is_duplicate\":y_pred})\n",
    "#prediction.to_csv(\"finalsubmission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
