{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import json\n",
    "import logging\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7f3905210f45d4bd698877d23aa572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style=u'info', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# init logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# init tqdm\n",
    "try:\n",
    "    if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "        tqdm_notebook().pandas()\n",
    "    else:\n",
    "        tqdm.pandas()\n",
    "except NameError:\n",
    "    tqdm.pandas()\n",
    "    \n",
    "# init stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train_data.csv')\n",
    "df_test = pd.read_csv('../data/test_data.csv')\n",
    "df_train_labels = pd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop('is_duplicate', axis = 1)\n",
    "df_train = df_train.merge(df_train_labels)\n",
    "\n",
    "#Drop rows with missing Qs\n",
    "df_train = df_train.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checklist:\n",
    "- Last Character (Question more likely to be duplicate if they end with same punctuation mark\n",
    "- Average Shared Words - Words shared by question pairs (more words shared = higher chance of duplicate)\n",
    "- Shared Entities (Enzo-engineered entities using spaCy)\n",
    "- Length (word count) - Words per sentence (Questions with different lengths they are unlikely to be duplicates) \n",
    "- Levenshtein Features - How many characters difference between two questions (more functions required = more dissimilar)\n",
    "- Tf-Idf \n",
    "- LDA (topic modelling)\n",
    "\n",
    "\n",
    "https://www.linkedin.com/pulse/kaggle-quora-question-pairs-mar-2017-may-priscilla-li/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience Method\n",
    "Rerun below cell, if you make an adjustment to any of the feature methods. Look at examples below for implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_FUNCTIONS = {\n",
    "    'last_char': get_last_char,\n",
    "    'avg_shared_words': get_shared_words,\n",
    "    'shared_word_percent': shared_word_pcnt,\n",
    "    'shared_bigrams': get_shared_bigrams,\n",
    "    'shared_bigrams_percent': get_shared_bigrams_pcnt,\n",
    "    'shared_trigrams': get_shared_trigrams,\n",
    "    'shared_trigrams_percent': get_shared_trigrams_pcnt,\n",
    "    'shared_quadgrams': get_shared_quadgrams,\n",
    "    'shared_quadgrams_percent': get_shared_quadgrams_pcnt,\n",
    "    'shared_entities': get_shared_entities,\n",
    "    'word_count_diff': get_word_count_diff,\n",
    "    'levenshtein': get_levenshtein_distance,\n",
    "    'get_tfidf': get_tfidf,\n",
    "}\n",
    "\n",
    "def get_features(df, feature_list):\n",
    "    \"\"\"\n",
    "    Convenience method to extract text features in the same way independent of the \n",
    "    dataframe. Ideally this method will be called with a list of feature names as\n",
    "    a list, which will also work as column names to limit any dataframe to the relevant\n",
    "    features.\n",
    "    \n",
    "    Hint: As pandas dataframes are merely pointers, we can get away with not returning\n",
    "          the manipulated dataframe as every instance of df will already be affected.\n",
    "    \n",
    "    Parameters\n",
    "        df: dataframe the features will be extracted from\n",
    "        feature_list: list object, containing all features as strings\n",
    "        \n",
    "    Returns\n",
    "        none: dataframe object is already manipulated and is not needed to be passed back\n",
    "    \"\"\"\n",
    "    for feature in feature_list:\n",
    "        logging.info('getting {}'.format(feature))\n",
    "        FEATURE_FUNCTIONS[feature](df)\n",
    "    logging.info('feature extraction done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:getting shared_quadgrams\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539869eefc1b4c14a2372daf026231b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:getting shared_quadgrams_percent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b128302f6c4d30a2bf96bfc701a793"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:feature extraction done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>avg_shared_bigrams</th>\n",
       "      <th>shared_bigram_pcnt</th>\n",
       "      <th>avg_shared_trigrams</th>\n",
       "      <th>shared_trigram_pcnt</th>\n",
       "      <th>avg_shared_quadgrams</th>\n",
       "      <th>shared_quadgram_pcnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>What would a Trump presidency mean for current...</td>\n",
       "      <td>How will a Trump presidency affect the student...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Why do rockets look white?</td>\n",
       "      <td>Why are rockets and boosters painted white?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>What's causing someone to be jealous?</td>\n",
       "      <td>What can I do to avoid being jealous of someone?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>How much is 30 kV in HP?</td>\n",
       "      <td>Where can I find a conversion chart for CC to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>What is the best travel website in spain?</td>\n",
       "      <td>What is the best travel website?</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0       15  What would a Trump presidency mean for current...   \n",
       "1       20                         Why do rockets look white?   \n",
       "2       21              What's causing someone to be jealous?   \n",
       "3       23                           How much is 30 kV in HP?   \n",
       "4       34          What is the best travel website in spain?   \n",
       "\n",
       "                                           question2  avg_shared_bigrams  \\\n",
       "0  How will a Trump presidency affect the student...                   2   \n",
       "1        Why are rockets and boosters painted white?                   0   \n",
       "2   What can I do to avoid being jealous of someone?                   0   \n",
       "3  Where can I find a conversion chart for CC to ...                   0   \n",
       "4                   What is the best travel website?                   4   \n",
       "\n",
       "   shared_bigram_pcnt  avg_shared_trigrams  shared_trigram_pcnt  \\\n",
       "0            0.133333                    1             0.071429   \n",
       "1            0.000000                    0             0.000000   \n",
       "2            0.000000                    0             0.000000   \n",
       "3            0.000000                    0             0.000000   \n",
       "4            0.666667                    3             0.600000   \n",
       "\n",
       "   avg_shared_quadgrams  shared_quadgram_pcnt  \n",
       "0                     0                   0.0  \n",
       "1                     0                   0.0  \n",
       "2                     0                   0.0  \n",
       "3                     0                   0.0  \n",
       "4                     2                   0.5  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Example 1 ===\n",
    "get_features(df_test, ['last_char', 'avg_shared_words', 'word_count_diff', 'shared_entities', 'levenshtein', 'shared_word_percent'])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:getting shared_entities\n",
      "INFO:root:converting entity 1 string representation to dictionaries\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafd7c0a49f4450980534b344e1c3f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=81126), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:converting entity 2 string representation to dictionaries\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c212ff44f38469390f3f2a6058d5fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=81126), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:looking up shared entities\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d870461b04d4e1ca520c89419d1c97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=81126), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:feature extraction done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>entities1</th>\n",
       "      <th>entities2</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>shared_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>invalid</td>\n",
       "      <td>How will a Trump presidency affect the student...</td>\n",
       "      <td>None</td>\n",
       "      <td>{u'ORG': 1, u'GPE': 2}</td>\n",
       "      <td>0.235347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>Why do rockets look white?</td>\n",
       "      <td>Why are rockets and boosters painted white?</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.892270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>What's causing someone to be jealous?</td>\n",
       "      <td>What can I do to avoid being jealous of someone?</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.956441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>How much is 30 kV in HP?</td>\n",
       "      <td>Where can I find a conversion chart for CC to ...</td>\n",
       "      <td>{u'PRODUCT': 1, u'QUANTITY': 1}</td>\n",
       "      <td>{u'ORG': 1}</td>\n",
       "      <td>0.835993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>What is the best travel website in spain?</td>\n",
       "      <td>What is the best travel website?</td>\n",
       "      <td>{u'GPE': 1}</td>\n",
       "      <td>None</td>\n",
       "      <td>0.968766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  test_id                                  question1  \\\n",
       "0           0       15                                    invalid   \n",
       "1           1       20                 Why do rockets look white?   \n",
       "2           2       21      What's causing someone to be jealous?   \n",
       "3           3       23                   How much is 30 kV in HP?   \n",
       "4           4       34  What is the best travel website in spain?   \n",
       "\n",
       "                                           question2  \\\n",
       "0  How will a Trump presidency affect the student...   \n",
       "1        Why are rockets and boosters painted white?   \n",
       "2   What can I do to avoid being jealous of someone?   \n",
       "3  Where can I find a conversion chart for CC to ...   \n",
       "4                   What is the best travel website?   \n",
       "\n",
       "                         entities1               entities2  similarity_score  \\\n",
       "0                             None  {u'ORG': 1, u'GPE': 2}          0.235347   \n",
       "1                             None                    None          0.892270   \n",
       "2                             None                    None          0.956441   \n",
       "3  {u'PRODUCT': 1, u'QUANTITY': 1}             {u'ORG': 1}          0.835993   \n",
       "4                      {u'GPE': 1}                    None          0.968766   \n",
       "\n",
       "   shared_entities  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Example 2 ===\n",
    "df_ents = pd.read_csv('data/test_with_sim_and_ents.csv')\n",
    "get_features(df_ents, ['shared_entities'])\n",
    "df_ents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Last Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_char(df):\n",
    "    df['last_char'] = np.where(df.question1.str[-1:] == df.question2.str[-1:], 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Avg. Shared Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove punctuation\n",
    "\n",
    "def shared_word_count(q1, q2):\n",
    "    return len([w for w in lower_list(q1.split(' ')) if w in lower_list(q2.split(' '))])\n",
    "\n",
    "def get_shared_words(df):\n",
    "    df['avg_shared_words'] = df.progress_apply(lambda row: shared_word_count(row['question1'],                                                                         \n",
    "                                                                             row['question2']), axis=1)\n",
    "    \n",
    "# Shared word percentage (0-100%)   \n",
    "def avg_word_count(q1, q2):\n",
    "    return (len(lower_list(q1.split(' '))) + len(lower_list(q2.split(' '))))/2.0\n",
    "    \n",
    "def shared_word_pcnt(df):\n",
    "    df['shared_words_pcnt'] = df.progress_apply(lambda row: shared_word_count(row['question1'], row['question2']) / avg_word_count(row['question1'], row['question2']), axis=1)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_ngram_count(q1, q2, n):\n",
    "    return len([w for w in ngrams(lower_list(q1.split(' ')), n) if w in ngrams(lower_list(q2.split(' ')), n)])\n",
    "\n",
    "def get_shared_ngrams(df, n):\n",
    "    df['avg_shared_{}grams'.format(n)] = df.progress_apply(lambda row: shared_bigram_count(row['question1'], row['question2']), axis=1)\n",
    "\n",
    "# percentage\n",
    "def ngram_count(q1, q2, n):\n",
    "    cnt = ((len([x for x in ngrams(lower_list(q1.split(' ')), n)]) + len([x for x in ngrams(lower_list(q2.split(' ')), n)])) / 2.0)\n",
    "    return cnt if cnt > 0 else 1\n",
    "            \n",
    "def shared_ngram_pcnt(df, n):\n",
    "    df['shared_{}grams_pcnt'.format(n)] = df.progress_apply(lambda row: shared_ngram_count(row['question1'], row['question2'], n) / ngram_count(row['question1'], row['question2'], n), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shared_bigrams(df):\n",
    "    get_shared_ngrams(df, 2)\n",
    "\n",
    "def get_shared_bigrams_pcnt(df):\n",
    "    shared_ngram_pcnt(df, 2)\n",
    "    \n",
    "def get_shared_trigrams(df):\n",
    "    get_shared_ngrams(df, 3)\n",
    "\n",
    "def get_shared_trigrams_pcnt(df):\n",
    "    shared_ngram_pcnt(df, 3)\n",
    "    \n",
    "def get_shared_quadgrams(df):\n",
    "    get_shared_ngrams(df, 4)\n",
    "\n",
    "def get_shared_quadgrams_pcnt(df):\n",
    "    shared_ngram_pcnt(df, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Shared Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITIES = {u'CARDINAL', u'DATE', u'EVENT', u'FAC', u'GPE', u'LANGUAGE', u'LAW', u'LOC', u'MONEY', u'NORP', u'ORDINAL',\n",
    "            u'ORG', u'PERCENT', u'PERSON', u'PRODUCT', u'QUANTITY', u'TIME', u'WORK_OF_ART'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Shared entities with half counts\n",
    "# TODO: Name the entities, if type matches, but instance is different it will be a good indicator\n",
    "\n",
    "def shared_keys(d1, d2):\n",
    "    d1 = {} if not isinstance(d1, dict) else d1\n",
    "    d2 = {} if not isinstance(d2, dict) else d2\n",
    "    return len([w for w in d1.keys() if w in d2.keys()])\n",
    "\n",
    "def non_shared_keys(d1, d2):\n",
    "    d1 = {} if not isinstance(d1, dict) else d1\n",
    "    d2 = {} if not isinstance(d2, dict) else d2\n",
    "    q1s = len([w for w in d1.keys() if w not in d2.keys()])\n",
    "    q2s = len([w for w in d2.keys() if w not in d1.keys()])\n",
    "    return q1s + q2s\n",
    "\n",
    "def get_shared_entities(df):\n",
    "    if 'entities1' not in df.columns or 'entities2' not in df.columns:\n",
    "        logging.warning('No entity dicts found in provided dataframe')\n",
    "        return\n",
    "    if isinstance(df.entities1[df.entities1.first_valid_index()], str):\n",
    "        logging.info('converting entity 1 string representation to dictionaries')\n",
    "        df.entities1 = df.entities1.progress_apply(lambda x: string_to_dict(x))\n",
    "    if isinstance(df.entities2[df.entities2.first_valid_index()], str):\n",
    "        logging.info('converting entity 2 string representation to dictionaries')\n",
    "        df.entities2 = df.entities2.progress_apply(lambda x: string_to_dict(x))\n",
    "    \n",
    "    logging.info('looking up shared entities')\n",
    "    df['shared_entities'] = df.progress_apply(lambda row: shared_keys(row['entities1'], \n",
    "                                                                      row['entities2']), axis=1)\n",
    "    df['non_shared_entities'] = df.progress_apply(lambda row: non_shared_keys(row['entities1'], \n",
    "                                                                              row['entities2']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Word Count Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_diff(q1, q2):\n",
    "    return abs(len(q1.split(' ')) - len(q2.split(' ')))\n",
    "\n",
    "def get_word_count_diff(df):\n",
    "    df['word_count_diff'] = df.progress_apply(lambda row: count_diff(row['question1'], \n",
    "                                                                     row['question2']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_levenshtein_distance(df):\n",
    "    # TODO: discuss if spaces should be considered in the distance calculation, add 'lambda x: x == \" \"' as first parameter to exclude spaces\n",
    "    df['levenshtein'] = df.progress_apply(lambda row: difflib.SequenceMatcher(None, \n",
    "                                                                              row['question1'], \n",
    "                                                                              row['question2']).ratio(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: code mostly copied, only adjusted the punctuation, stopwords and empty strings\n",
    "\n",
    "from collections import Counter\n",
    "def get_weights(df):\n",
    "# If a word appears only once, we ignore it completely (likely a typo)\n",
    "# Epsilon defines a smoothing constant, which makes the effect of extremely rare words smaller\n",
    "    def get_weight(count, eps=10000, min_count=2):\n",
    "        if count < min_count:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 1.0 / (count + eps)\n",
    "\n",
    "    eps = 5000 \n",
    "    words = (\" \".join(list(df.question1) + list(df.question2))).lower().split()\n",
    "    words = [remove_punctuation(w) for w in words]\n",
    "    words = [w if w not in STOPWORDS else '' for w in words]\n",
    "    words = filter(None, words)  # filter out empty strings\n",
    "    counts = Counter(words)\n",
    "    weights = {word: get_weight(count, eps) for word, count in counts.items()}\n",
    "    return weights\n",
    "    # print('Most common words and weights: \\n')\n",
    "    # print(sorted(weights.items(), key=lambda x: x[1] if x[1] > 0 else 9999)[:10])\n",
    "    # print('\\nLeast common words and weights: ')\n",
    "    # (sorted(weights.items(), key=lambda x: x[1], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: code copied\n",
    "\n",
    "def tfidf_word_match_share(row, weights):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in str(row['question1']).lower().split():\n",
    "        if word not in STOPWORDS:\n",
    "            q1words[word] = 1\n",
    "    for word in str(row['question2']).lower().split():\n",
    "        if word not in STOPWORDS:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    " \n",
    "    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n",
    "    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
    "    \n",
    "    R = np.sum(shared_weights) / np.sum(total_weights)\n",
    "    return R\n",
    "\n",
    "def get_tfidf(df):\n",
    "    weights = get_weights(df)\n",
    "    df['tfidf_word_match_share'] = df.progress_apply(lambda row: tfidf_word_match_share(row, weights), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_list(_list):\n",
    "    return [x.lower() for x in remove_punctuation(_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_dict(dict_string):\n",
    "    if isinstance(dict_string, str):\n",
    "        # Convert to proper json format\n",
    "        dict_string = dict_string.replace(\"'\", '\"').replace('u\"', '\"')\n",
    "        return json.loads(dict_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(string_):\n",
    "    return string_.translate(None, string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_ = [\n",
    "#    'last_char',\n",
    "#    'avg_shared_words',\n",
    "#    'word_count_diff',\n",
    "   'shared_entities',\n",
    "#    'levenshtein',\n",
    "#    'shared_word_percent',\n",
    "#    'shared_bigrams',\n",
    "#    'shared_bigrams_percent',\n",
    "#    'shared_trigrams',\n",
    "#    'shared_trigrams_percent',\n",
    "#    'shared_quadgrams',\n",
    "#    'shared_quadgrams_percent',\n",
    "#    'get_tfidf',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:getting get_tfidf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6befa70c1a14cd09b9e8f36b528e38d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/tom/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/Users/tom/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "INFO:root:feature extraction done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:getting get_tfidf\n"
     ]
    }
   ],
   "source": [
    "# train_data\n",
    "get_features(df_train, methods_)\n",
    "df_train.to_csv(\"tfidf_train_features.csv\", index=False)\n",
    "\n",
    "# test_data\n",
    "get_features(df_test, methods_)\n",
    "df_test.to_csv(\"tfidf_test_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add entity features to exported csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323162, Index([u'id', u'question1', u'question2', u'is_duplicate', u'last_char',\n",
      "       u'avg_shared_words', u'word_count_diff', u'levenshtein',\n",
      "       u'shared_words_pcnt', u'avg_shared_trigrams', u'shared_bigram_pcnt',\n",
      "       u'shared_trigram_pcnt', u'avg_shared_quadgrams',\n",
      "       u'shared_quadgram_pcnt', u'shared_entities', u'non_shared_entities'],\n",
      "      dtype='object'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>last_char</th>\n",
       "      <th>avg_shared_words</th>\n",
       "      <th>word_count_diff</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>shared_words_pcnt</th>\n",
       "      <th>avg_shared_trigrams</th>\n",
       "      <th>shared_bigram_pcnt</th>\n",
       "      <th>shared_trigram_pcnt</th>\n",
       "      <th>avg_shared_quadgrams</th>\n",
       "      <th>shared_quadgram_pcnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>202197.358130</td>\n",
       "      <td>0.368834</td>\n",
       "      <td>0.980159</td>\n",
       "      <td>4.790084</td>\n",
       "      <td>3.699067</td>\n",
       "      <td>0.579246</td>\n",
       "      <td>0.451941</td>\n",
       "      <td>1.365640</td>\n",
       "      <td>0.246312</td>\n",
       "      <td>0.153666</td>\n",
       "      <td>0.875412</td>\n",
       "      <td>0.102417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116794.725695</td>\n",
       "      <td>0.482489</td>\n",
       "      <td>0.139455</td>\n",
       "      <td>3.451633</td>\n",
       "      <td>4.842665</td>\n",
       "      <td>0.219205</td>\n",
       "      <td>0.257909</td>\n",
       "      <td>2.661596</td>\n",
       "      <td>0.259780</td>\n",
       "      <td>0.239070</td>\n",
       "      <td>2.310736</td>\n",
       "      <td>0.214343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100962.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.403670</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>202164.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>303538.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>404289.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.297297</td>\n",
       "      <td>1.257143</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.212121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id   is_duplicate      last_char  avg_shared_words  \\\n",
       "count  323162.000000  323162.000000  323162.000000     323162.000000   \n",
       "mean   202197.358130       0.368834       0.980159          4.790084   \n",
       "std    116794.725695       0.482489       0.139455          3.451633   \n",
       "min         0.000000       0.000000       0.000000          0.000000   \n",
       "25%    100962.250000       0.000000       1.000000          2.000000   \n",
       "50%    202164.500000       0.000000       1.000000          4.000000   \n",
       "75%    303538.750000       1.000000       1.000000          6.000000   \n",
       "max    404289.000000       1.000000       1.000000         61.000000   \n",
       "\n",
       "       word_count_diff    levenshtein  shared_words_pcnt  avg_shared_trigrams  \\\n",
       "count    323162.000000  323162.000000      323162.000000        323162.000000   \n",
       "mean          3.699067       0.579246           0.451941             1.365640   \n",
       "std           4.842665       0.219205           0.257909             2.661596   \n",
       "min           0.000000       0.000000           0.000000             0.000000   \n",
       "25%           1.000000       0.403670           0.250000             0.000000   \n",
       "50%           2.000000       0.582278           0.444444             0.000000   \n",
       "75%           5.000000       0.756757           0.645161             2.000000   \n",
       "max         223.000000       1.000000           1.333333            52.000000   \n",
       "\n",
       "       shared_bigram_pcnt  shared_trigram_pcnt  avg_shared_quadgrams  \\\n",
       "count       323162.000000        323162.000000         323162.000000   \n",
       "mean             0.246312             0.153666              0.875412   \n",
       "std              0.259780             0.239070              2.310736   \n",
       "min              0.000000             0.000000              0.000000   \n",
       "25%              0.000000             0.000000              0.000000   \n",
       "50%              0.166667             0.000000              0.000000   \n",
       "75%              0.400000             0.235294              1.000000   \n",
       "max              1.297297             1.257143             48.000000   \n",
       "\n",
       "       shared_quadgram_pcnt  \n",
       "count         323162.000000  \n",
       "mean               0.102417  \n",
       "std                0.214343  \n",
       "min                0.000000  \n",
       "25%                0.000000  \n",
       "50%                0.000000  \n",
       "75%                0.080000  \n",
       "max                1.212121  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/train_features.csv')\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>last_char</th>\n",
       "      <th>avg_shared_words</th>\n",
       "      <th>word_count_diff</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>shared_words_pcnt</th>\n",
       "      <th>avg_shared_trigrams</th>\n",
       "      <th>shared_bigram_pcnt</th>\n",
       "      <th>shared_trigram_pcnt</th>\n",
       "      <th>avg_shared_quadgrams</th>\n",
       "      <th>shared_quadgram_pcnt</th>\n",
       "      <th>shared_entities</th>\n",
       "      <th>non_shared_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "      <td>323162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>202197.358130</td>\n",
       "      <td>0.368834</td>\n",
       "      <td>0.980159</td>\n",
       "      <td>4.790084</td>\n",
       "      <td>3.699067</td>\n",
       "      <td>0.579246</td>\n",
       "      <td>0.451941</td>\n",
       "      <td>1.365640</td>\n",
       "      <td>0.246312</td>\n",
       "      <td>0.153666</td>\n",
       "      <td>0.875412</td>\n",
       "      <td>0.102417</td>\n",
       "      <td>0.384142</td>\n",
       "      <td>0.577404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116794.725695</td>\n",
       "      <td>0.482489</td>\n",
       "      <td>0.139455</td>\n",
       "      <td>3.451633</td>\n",
       "      <td>4.842665</td>\n",
       "      <td>0.219205</td>\n",
       "      <td>0.257909</td>\n",
       "      <td>2.661596</td>\n",
       "      <td>0.259780</td>\n",
       "      <td>0.239070</td>\n",
       "      <td>2.310736</td>\n",
       "      <td>0.214343</td>\n",
       "      <td>0.586787</td>\n",
       "      <td>0.871758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100962.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.403670</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>202164.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>303538.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>404289.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.297297</td>\n",
       "      <td>1.257143</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.212121</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id   is_duplicate      last_char  avg_shared_words  \\\n",
       "count  323162.000000  323162.000000  323162.000000     323162.000000   \n",
       "mean   202197.358130       0.368834       0.980159          4.790084   \n",
       "std    116794.725695       0.482489       0.139455          3.451633   \n",
       "min         0.000000       0.000000       0.000000          0.000000   \n",
       "25%    100962.250000       0.000000       1.000000          2.000000   \n",
       "50%    202164.500000       0.000000       1.000000          4.000000   \n",
       "75%    303538.750000       1.000000       1.000000          6.000000   \n",
       "max    404289.000000       1.000000       1.000000         61.000000   \n",
       "\n",
       "       word_count_diff    levenshtein  shared_words_pcnt  avg_shared_trigrams  \\\n",
       "count    323162.000000  323162.000000      323162.000000        323162.000000   \n",
       "mean          3.699067       0.579246           0.451941             1.365640   \n",
       "std           4.842665       0.219205           0.257909             2.661596   \n",
       "min           0.000000       0.000000           0.000000             0.000000   \n",
       "25%           1.000000       0.403670           0.250000             0.000000   \n",
       "50%           2.000000       0.582278           0.444444             0.000000   \n",
       "75%           5.000000       0.756757           0.645161             2.000000   \n",
       "max         223.000000       1.000000           1.333333            52.000000   \n",
       "\n",
       "       shared_bigram_pcnt  shared_trigram_pcnt  avg_shared_quadgrams  \\\n",
       "count       323162.000000        323162.000000         323162.000000   \n",
       "mean             0.246312             0.153666              0.875412   \n",
       "std              0.259780             0.239070              2.310736   \n",
       "min              0.000000             0.000000              0.000000   \n",
       "25%              0.000000             0.000000              0.000000   \n",
       "50%              0.166667             0.000000              0.000000   \n",
       "75%              0.400000             0.235294              1.000000   \n",
       "max              1.297297             1.257143             48.000000   \n",
       "\n",
       "       shared_quadgram_pcnt  shared_entities  non_shared_entities  \n",
       "count         323162.000000    323162.000000        323162.000000  \n",
       "mean               0.102417         0.384142             0.577404  \n",
       "std                0.214343         0.586787             0.871758  \n",
       "min                0.000000         0.000000             0.000000  \n",
       "25%                0.000000         0.000000             0.000000  \n",
       "50%                0.000000         0.000000             0.000000  \n",
       "75%                0.080000         1.000000             1.000000  \n",
       "max                1.212121         6.000000             8.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ents = pd.read_csv('../data/train_with_sim_and_ents_long.csv')\n",
    "get_features(df_train_ents, methods_)\n",
    "df_train = df_train.merge(df_train_ents.loc[:,['id','shared_entities','non_shared_entities']] , on='id', how='left')\n",
    "df_train.shared_entities = df_train.shared_entities.fillna(0).astype(int)\n",
    "df_train.non_shared_entities = df_train.non_shared_entities.fillna(0).astype(int)\n",
    "df_train.to_csv('../data/train_features.csv')\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>last_char</th>\n",
       "      <th>avg_shared_words</th>\n",
       "      <th>word_count_diff</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>shared_words_pcnt</th>\n",
       "      <th>avg_shared_trigrams</th>\n",
       "      <th>shared_bigram_pcnt</th>\n",
       "      <th>shared_trigram_pcnt</th>\n",
       "      <th>avg_shared_quadgrams</th>\n",
       "      <th>shared_quadgram_pcnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>201935.133447</td>\n",
       "      <td>0.980426</td>\n",
       "      <td>4.784866</td>\n",
       "      <td>3.684787</td>\n",
       "      <td>0.578928</td>\n",
       "      <td>0.452134</td>\n",
       "      <td>1.358985</td>\n",
       "      <td>0.246322</td>\n",
       "      <td>0.153545</td>\n",
       "      <td>0.870116</td>\n",
       "      <td>0.102297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116366.394811</td>\n",
       "      <td>0.138534</td>\n",
       "      <td>3.449371</td>\n",
       "      <td>4.825042</td>\n",
       "      <td>0.218786</td>\n",
       "      <td>0.257994</td>\n",
       "      <td>2.654754</td>\n",
       "      <td>0.260056</td>\n",
       "      <td>0.239421</td>\n",
       "      <td>2.303912</td>\n",
       "      <td>0.214581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101527.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.404145</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>202071.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>301947.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>404278.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test_id     last_char  avg_shared_words  word_count_diff  \\\n",
       "count   81126.000000  81126.000000      81126.000000     81126.000000   \n",
       "mean   201935.133447      0.980426          4.784866         3.684787   \n",
       "std    116366.394811      0.138534          3.449371         4.825042   \n",
       "min        15.000000      0.000000          0.000000         0.000000   \n",
       "25%    101527.000000      1.000000          3.000000         1.000000   \n",
       "50%    202071.500000      1.000000          4.000000         2.000000   \n",
       "75%    301947.750000      1.000000          6.000000         5.000000   \n",
       "max    404278.000000      1.000000         50.000000       213.000000   \n",
       "\n",
       "        levenshtein  shared_words_pcnt  avg_shared_trigrams  \\\n",
       "count  81126.000000       81126.000000         81126.000000   \n",
       "mean       0.578928           0.452134             1.358985   \n",
       "std        0.218786           0.257994             2.654754   \n",
       "min        0.000000           0.000000             0.000000   \n",
       "25%        0.404145           0.250000             0.000000   \n",
       "50%        0.581197           0.444444             0.000000   \n",
       "75%        0.755556           0.647059             2.000000   \n",
       "max        1.000000           1.285714            42.000000   \n",
       "\n",
       "       shared_bigram_pcnt  shared_trigram_pcnt  avg_shared_quadgrams  \\\n",
       "count        81126.000000         81126.000000          81126.000000   \n",
       "mean             0.246322             0.153545              0.870116   \n",
       "std              0.260056             0.239421              2.303912   \n",
       "min              0.000000             0.000000              0.000000   \n",
       "25%              0.000000             0.000000              0.000000   \n",
       "50%              0.166667             0.000000              0.000000   \n",
       "75%              0.400000             0.235294              1.000000   \n",
       "max              1.166667             1.000000             40.000000   \n",
       "\n",
       "       shared_quadgram_pcnt  \n",
       "count          81126.000000  \n",
       "mean               0.102297  \n",
       "std                0.214581  \n",
       "min                0.000000  \n",
       "25%                0.000000  \n",
       "50%                0.000000  \n",
       "75%                0.080000  \n",
       "max                1.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('../data/test_features.csv')\n",
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>last_char</th>\n",
       "      <th>avg_shared_words</th>\n",
       "      <th>word_count_diff</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>shared_words_pcnt</th>\n",
       "      <th>avg_shared_trigrams</th>\n",
       "      <th>shared_bigram_pcnt</th>\n",
       "      <th>shared_trigram_pcnt</th>\n",
       "      <th>avg_shared_quadgrams</th>\n",
       "      <th>shared_quadgram_pcnt</th>\n",
       "      <th>shared_entities</th>\n",
       "      <th>non_shared_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>201935.133447</td>\n",
       "      <td>0.980426</td>\n",
       "      <td>4.784866</td>\n",
       "      <td>3.684787</td>\n",
       "      <td>0.578928</td>\n",
       "      <td>0.452134</td>\n",
       "      <td>1.358985</td>\n",
       "      <td>0.246322</td>\n",
       "      <td>0.153545</td>\n",
       "      <td>0.870116</td>\n",
       "      <td>0.102297</td>\n",
       "      <td>0.386572</td>\n",
       "      <td>0.576622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116366.394811</td>\n",
       "      <td>0.138534</td>\n",
       "      <td>3.449371</td>\n",
       "      <td>4.825042</td>\n",
       "      <td>0.218786</td>\n",
       "      <td>0.257994</td>\n",
       "      <td>2.654754</td>\n",
       "      <td>0.260056</td>\n",
       "      <td>0.239421</td>\n",
       "      <td>2.303912</td>\n",
       "      <td>0.214581</td>\n",
       "      <td>0.586796</td>\n",
       "      <td>0.869147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101527.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.404145</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>202071.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>301947.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>404278.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test_id     last_char  avg_shared_words  word_count_diff  \\\n",
       "count   81126.000000  81126.000000      81126.000000     81126.000000   \n",
       "mean   201935.133447      0.980426          4.784866         3.684787   \n",
       "std    116366.394811      0.138534          3.449371         4.825042   \n",
       "min        15.000000      0.000000          0.000000         0.000000   \n",
       "25%    101527.000000      1.000000          3.000000         1.000000   \n",
       "50%    202071.500000      1.000000          4.000000         2.000000   \n",
       "75%    301947.750000      1.000000          6.000000         5.000000   \n",
       "max    404278.000000      1.000000         50.000000       213.000000   \n",
       "\n",
       "        levenshtein  shared_words_pcnt  avg_shared_trigrams  \\\n",
       "count  81126.000000       81126.000000         81126.000000   \n",
       "mean       0.578928           0.452134             1.358985   \n",
       "std        0.218786           0.257994             2.654754   \n",
       "min        0.000000           0.000000             0.000000   \n",
       "25%        0.404145           0.250000             0.000000   \n",
       "50%        0.581197           0.444444             0.000000   \n",
       "75%        0.755556           0.647059             2.000000   \n",
       "max        1.000000           1.285714            42.000000   \n",
       "\n",
       "       shared_bigram_pcnt  shared_trigram_pcnt  avg_shared_quadgrams  \\\n",
       "count        81126.000000         81126.000000          81126.000000   \n",
       "mean             0.246322             0.153545              0.870116   \n",
       "std              0.260056             0.239421              2.303912   \n",
       "min              0.000000             0.000000              0.000000   \n",
       "25%              0.000000             0.000000              0.000000   \n",
       "50%              0.166667             0.000000              0.000000   \n",
       "75%              0.400000             0.235294              1.000000   \n",
       "max              1.166667             1.000000             40.000000   \n",
       "\n",
       "       shared_quadgram_pcnt  shared_entities  non_shared_entities  \n",
       "count          81126.000000     81126.000000         81126.000000  \n",
       "mean               0.102297         0.386572             0.576622  \n",
       "std                0.214581         0.586796             0.869147  \n",
       "min                0.000000         0.000000             0.000000  \n",
       "25%                0.000000         0.000000             0.000000  \n",
       "50%                0.000000         0.000000             0.000000  \n",
       "75%                0.080000         1.000000             1.000000  \n",
       "max                1.000000         5.000000             7.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_ents = pd.read_csv('../data/test_with_sim_and_ents_long.csv')\n",
    "get_features(df_test_ents, methods_)\n",
    "df_test = df_test.merge(df_test_ents.loc[:,['test_id','shared_entities','non_shared_entities']] , on='test_id', how='left')\n",
    "df_test.shared_entities = df_test.shared_entities.fillna(0).astype(int)\n",
    "df_test.non_shared_entities = df_test.non_shared_entities.fillna(0).astype(int)\n",
    "df_test.to_csv('../data/train_features.csv')\n",
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
