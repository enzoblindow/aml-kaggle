{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from helpers import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035c7d1b285a450e84c121db0a7eba2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style=u'info', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# init logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# init tqdm\n",
    "try:\n",
    "    if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "        tqdm_notebook().pandas()\n",
    "    else:\n",
    "        tqdm.pandas()\n",
    "except NameError:\n",
    "    tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dfs = [\n",
    "    {\n",
    "        'df': '../data/{}_features.csv',\n",
    "        'cols': [\n",
    "            'last_char',\n",
    "             'avg_shared_words',\n",
    "             'word_count_diff',\n",
    "             'levenshtein',\n",
    "             'shared_words_pcnt',\n",
    "             'avg_shared_trigrams',\n",
    "             'shared_bigram_pcnt',\n",
    "             'shared_trigram_pcnt',\n",
    "             'avg_shared_quadgrams',\n",
    "             'shared_quadgram_pcnt',\n",
    "             'shared_entities',\n",
    "             'non_shared_entities',\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'df': '../data/{}_lstm_output.csv',\n",
    "        'cols': [\n",
    "            'nn_out'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'df': '../data/tfidf_{}_features.csv',\n",
    "        'cols': [\n",
    "            'tfidf_word_match_share'\n",
    "        ]\n",
    "    },\n",
    "#     {\n",
    "#         'df': '../data/topic_modelling_output.csv',\n",
    "#         'cols': []\n",
    "#     },\n",
    "    {\n",
    "        'df': '../data/{}_with_sim_and_ents_long.csv',\n",
    "        'cols': [\n",
    "            'CARDINAL_1','DATE_1','EVENT_1','FAC_1','GPE_1','LANGUAGE_1','LAW_1','LOC_1','MONEY_1','NORP_1',\n",
    "            'ORDINAL_1','ORG_1','PERCENT_1','PERSON_1','PRODUCT_1','QUANTITY_1','TIME_1','WORK_OF_ART_1',\n",
    "            'CARDINAL_2','DATE_2','EVENT_2','FAC_2','GPE_2','LANGUAGE_2','LAW_2','LOC_2','MONEY_2','NORP_2',\n",
    "            'ORDINAL_2','ORG_2','PERCENT_2','PERSON_2','PRODUCT_2','QUANTITY_2','TIME_2','WORK_OF_ART_2',\n",
    "        ]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df(df, merge_col='id', _set='train'):\n",
    "    \"\"\"\n",
    "    Creates the dataframe for either train or test set identically.\n",
    "    \n",
    "    Parameter\n",
    "        df: base dataframe containing the ids and questions\n",
    "        merge_col: specify the column name how to merge the dataframe together\n",
    "        _set: pass either 'test' or 'train'\n",
    "        \n",
    "    Returns\n",
    "        df: fully merged dataframe\n",
    "    \"\"\"\n",
    "    for _df in _dfs:\n",
    "        path = _df['df'].format(_set)\n",
    "        df = df.merge(pd.read_csv(path).loc[:,[merge_col] + _df['cols']], on=merge_col, how='left')\n",
    "        logging.info('Merged in {}'.format(path))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_set(df, preds_array, file_path):\n",
    "    \"\"\"\n",
    "    Builds the csv in the format that can be uploaded to kaggle.\n",
    "    \n",
    "    Parameter\n",
    "        df: test dataframe containing the test ids and that was used to make the predictions\n",
    "        preds_array: the predicition array that was return by the model\n",
    "        file_path: specify the path and file name to store the output csv\n",
    "    \"\"\"\n",
    "    p = pd.DataFrame({\"test_id\": df['test_id']})\n",
    "    p['is_duplicate'] = preds_array\n",
    "    p['is_duplicate'] = np.around(p['is_duplicate'].values)\n",
    "    p.is_duplicate = p.is_duplicate.astype(int)\n",
    "    p.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train_data.csv')\n",
    "df_train = df_train.drop(['is_duplicate'], axis=1).merge(pd.read_csv('../data/train_labels.csv'), on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Merged in ../data/train_features.csv\n",
      "INFO:root:Merged in ../data/train_lstm_output.csv\n",
      "INFO:root:Merged in ../data/tfidf_train_features.csv\n",
      "INFO:root:Merged in ../data/train_with_sim_and_ents_long.csv\n"
     ]
    }
   ],
   "source": [
    "df_train = build_df(df_train, merge_col='id', _set='train')\n",
    "df_train = df_train.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Merged in ../data/test_features.csv\n",
      "INFO:root:Merged in ../data/test_lstm_output.csv\n",
      "INFO:root:Merged in ../data/tfidf_test_features.csv\n",
      "INFO:root:Merged in ../data/test_with_sim_and_ents_long.csv\n"
     ]
    }
   ],
   "source": [
    "df_test = build_df(df_test, merge_col='test_id', _set='test')\n",
    "df_test = df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "1. Logistic Regression\n",
    "2. Stepwise Logistic Regression\n",
    "3. Decision Tree\n",
    "4. Random Forest\n",
    "5. SVM\n",
    "6. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>last_char</th>\n",
       "      <th>avg_shared_words</th>\n",
       "      <th>word_count_diff</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>shared_words_pcnt</th>\n",
       "      <th>avg_shared_trigrams</th>\n",
       "      <th>shared_bigram_pcnt</th>\n",
       "      <th>shared_trigram_pcnt</th>\n",
       "      <th>avg_shared_quadgrams</th>\n",
       "      <th>...</th>\n",
       "      <th>MONEY_2</th>\n",
       "      <th>NORP_2</th>\n",
       "      <th>ORDINAL_2</th>\n",
       "      <th>ORG_2</th>\n",
       "      <th>PERCENT_2</th>\n",
       "      <th>PERSON_2</th>\n",
       "      <th>PRODUCT_2</th>\n",
       "      <th>QUANTITY_2</th>\n",
       "      <th>TIME_2</th>\n",
       "      <th>WORK_OF_ART_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "      <td>81126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>201935.133447</td>\n",
       "      <td>0.980426</td>\n",
       "      <td>4.784866</td>\n",
       "      <td>3.684787</td>\n",
       "      <td>0.578928</td>\n",
       "      <td>0.452134</td>\n",
       "      <td>1.358985</td>\n",
       "      <td>0.246322</td>\n",
       "      <td>0.153545</td>\n",
       "      <td>0.870116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.058230</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.203794</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.117139</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.008431</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.013756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116366.394811</td>\n",
       "      <td>0.138534</td>\n",
       "      <td>3.449371</td>\n",
       "      <td>4.825042</td>\n",
       "      <td>0.218786</td>\n",
       "      <td>0.257994</td>\n",
       "      <td>2.654754</td>\n",
       "      <td>0.260056</td>\n",
       "      <td>0.239421</td>\n",
       "      <td>2.303912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078568</td>\n",
       "      <td>0.283124</td>\n",
       "      <td>0.121828</td>\n",
       "      <td>0.504203</td>\n",
       "      <td>0.058595</td>\n",
       "      <td>0.379341</td>\n",
       "      <td>0.143036</td>\n",
       "      <td>0.104637</td>\n",
       "      <td>0.096356</td>\n",
       "      <td>0.120433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101527.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.404145</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>202071.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>301947.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>404278.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             test_id     last_char  avg_shared_words  word_count_diff  \\\n",
       "count   81126.000000  81126.000000      81126.000000     81126.000000   \n",
       "mean   201935.133447      0.980426          4.784866         3.684787   \n",
       "std    116366.394811      0.138534          3.449371         4.825042   \n",
       "min        15.000000      0.000000          0.000000         0.000000   \n",
       "25%    101527.000000      1.000000          3.000000         1.000000   \n",
       "50%    202071.500000      1.000000          4.000000         2.000000   \n",
       "75%    301947.750000      1.000000          6.000000         5.000000   \n",
       "max    404278.000000      1.000000         50.000000       213.000000   \n",
       "\n",
       "        levenshtein  shared_words_pcnt  avg_shared_trigrams  \\\n",
       "count  81126.000000       81126.000000         81126.000000   \n",
       "mean       0.578928           0.452134             1.358985   \n",
       "std        0.218786           0.257994             2.654754   \n",
       "min        0.000000           0.000000             0.000000   \n",
       "25%        0.404145           0.250000             0.000000   \n",
       "50%        0.581197           0.444444             0.000000   \n",
       "75%        0.755556           0.647059             2.000000   \n",
       "max        1.000000           1.285714            42.000000   \n",
       "\n",
       "       shared_bigram_pcnt  shared_trigram_pcnt  avg_shared_quadgrams  \\\n",
       "count        81126.000000         81126.000000          81126.000000   \n",
       "mean             0.246322             0.153545              0.870116   \n",
       "std              0.260056             0.239421              2.303912   \n",
       "min              0.000000             0.000000              0.000000   \n",
       "25%              0.000000             0.000000              0.000000   \n",
       "50%              0.166667             0.000000              0.000000   \n",
       "75%              0.400000             0.235294              1.000000   \n",
       "max              1.166667             1.000000             40.000000   \n",
       "\n",
       "           ...             MONEY_2        NORP_2     ORDINAL_2         ORG_2  \\\n",
       "count      ...        81126.000000  81126.000000  81126.000000  81126.000000   \n",
       "mean       ...            0.005239      0.058230      0.013571      0.203794   \n",
       "std        ...            0.078568      0.283124      0.121828      0.504203   \n",
       "min        ...            0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...            0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...            0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...            0.000000      0.000000      0.000000      0.000000   \n",
       "max        ...            3.000000      6.000000      3.000000      7.000000   \n",
       "\n",
       "          PERCENT_2      PERSON_2     PRODUCT_2    QUANTITY_2        TIME_2  \\\n",
       "count  81126.000000  81126.000000  81126.000000  81126.000000  81126.000000   \n",
       "mean       0.002404      0.117139      0.016924      0.008431      0.007692   \n",
       "std        0.058595      0.379341      0.143036      0.104637      0.096356   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        4.000000      8.000000      4.000000      6.000000      4.000000   \n",
       "\n",
       "       WORK_OF_ART_2  \n",
       "count   81126.000000  \n",
       "mean        0.013756  \n",
       "std         0.120433  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         3.000000  \n",
       "\n",
       "[8 rows x 51 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_char</th>\n",
       "      <th>avg_shared_words</th>\n",
       "      <th>word_count_diff</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>shared_words_pcnt</th>\n",
       "      <th>avg_shared_trigrams</th>\n",
       "      <th>shared_bigram_pcnt</th>\n",
       "      <th>shared_trigram_pcnt</th>\n",
       "      <th>avg_shared_quadgrams</th>\n",
       "      <th>shared_quadgram_pcnt</th>\n",
       "      <th>...</th>\n",
       "      <th>MONEY_2</th>\n",
       "      <th>NORP_2</th>\n",
       "      <th>ORDINAL_2</th>\n",
       "      <th>ORG_2</th>\n",
       "      <th>PERCENT_2</th>\n",
       "      <th>PERSON_2</th>\n",
       "      <th>PRODUCT_2</th>\n",
       "      <th>QUANTITY_2</th>\n",
       "      <th>TIME_2</th>\n",
       "      <th>WORK_OF_ART_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.647482</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.365217</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   last_char  avg_shared_words  word_count_diff  levenshtein  \\\n",
       "0        1.0              12.0              2.0     0.926829   \n",
       "1        1.0               4.0              5.0     0.647482   \n",
       "2        1.0               4.0              4.0     0.454545   \n",
       "3        1.0               0.0              2.0     0.069565   \n",
       "4        1.0               2.0              6.0     0.365217   \n",
       "\n",
       "   shared_words_pcnt  avg_shared_trigrams  shared_bigram_pcnt  \\\n",
       "0           0.923077                  9.0            0.833333   \n",
       "1           0.380952                  0.0            0.105263   \n",
       "2           0.333333                  0.0            0.090909   \n",
       "3           0.000000                  0.0            0.000000   \n",
       "4           0.200000                  0.0            0.000000   \n",
       "\n",
       "   shared_trigram_pcnt  avg_shared_quadgrams  shared_quadgram_pcnt  \\\n",
       "0             0.818182                   8.0                   0.8   \n",
       "1             0.000000                   0.0                   0.0   \n",
       "2             0.000000                   0.0                   0.0   \n",
       "3             0.000000                   0.0                   0.0   \n",
       "4             0.000000                   0.0                   0.0   \n",
       "\n",
       "       ...        MONEY_2  NORP_2  ORDINAL_2  ORG_2  PERCENT_2  PERSON_2  \\\n",
       "0      ...            0.0     0.0        0.0    0.0        0.0       0.0   \n",
       "1      ...            0.0     1.0        0.0    0.0        0.0       2.0   \n",
       "2      ...            0.0     0.0        0.0    1.0        0.0       0.0   \n",
       "3      ...            0.0     0.0        0.0    0.0        0.0       0.0   \n",
       "4      ...            0.0     0.0        0.0    0.0        0.0       0.0   \n",
       "\n",
       "   PRODUCT_2  QUANTITY_2  TIME_2  WORK_OF_ART_2  \n",
       "0        0.0         0.0     0.0            0.0  \n",
       "1        0.0         0.0     0.0            0.0  \n",
       "2        0.0         0.0     0.0            0.0  \n",
       "3        0.0         0.0     0.0            0.0  \n",
       "4        0.0         0.0     0.0            0.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_train['is_duplicate']\n",
    "x = df_train.drop(['id', 'question1', 'question2', 'is_duplicate'], axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.150956\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           is_duplicate   No. Observations:               323164\n",
      "Model:                          Logit   Df Residuals:                   323114\n",
      "Method:                           MLE   Df Model:                           49\n",
      "Date:                Sun, 03 Dec 2017   Pseudo R-squ.:                  0.7707\n",
      "Time:                        14:36:28   Log-Likelihood:                -48784.\n",
      "converged:                       True   LL-Null:                   -2.1275e+05\n",
      "                                        LLR p-value:                     0.000\n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "last_char                 -3.4974      0.036    -95.851      0.000      -3.569      -3.426\n",
      "avg_shared_words          -0.0619      0.008     -7.445      0.000      -0.078      -0.046\n",
      "word_count_diff           -0.0969      0.003    -34.081      0.000      -0.103      -0.091\n",
      "levenshtein               -2.5782      0.085    -30.302      0.000      -2.745      -2.411\n",
      "shared_words_pcnt          2.8579      0.142     20.143      0.000       2.580       3.136\n",
      "avg_shared_trigrams        0.6832      0.041     16.861      0.000       0.604       0.763\n",
      "shared_bigram_pcnt         0.3208      0.150      2.135      0.033       0.026       0.615\n",
      "shared_trigram_pcnt       -4.0304      0.288    -14.019      0.000      -4.594      -3.467\n",
      "avg_shared_quadgrams      -0.5560      0.039    -14.281      0.000      -0.632      -0.480\n",
      "shared_quadgram_pcnt       1.1683      0.239      4.878      0.000       0.699       1.638\n",
      "shared_entities            0.2866      0.040      7.163      0.000       0.208       0.365\n",
      "non_shared_entities       -0.1751      0.021     -8.318      0.000      -0.216      -0.134\n",
      "nn_out                     6.7326      0.022    302.708      0.000       6.689       6.776\n",
      "tfidf_word_match_share     0.9388      0.040     23.362      0.000       0.860       1.018\n",
      "CARDINAL_1                 0.0095      0.039      0.245      0.806      -0.066       0.085\n",
      "DATE_1                    -0.0397      0.041     -0.958      0.338      -0.121       0.041\n",
      "EVENT_1                    0.0443      0.125      0.356      0.722      -0.200       0.288\n",
      "FAC_1                      0.0728      0.175      0.416      0.678      -0.270       0.416\n",
      "GPE_1                     -0.1189      0.033     -3.619      0.000      -0.183      -0.055\n",
      "LANGUAGE_1                -0.1081      0.109     -0.993      0.321      -0.321       0.105\n",
      "LAW_1                      0.0548      0.227      0.242      0.809      -0.389       0.499\n",
      "LOC_1                      0.1966      0.080      2.472      0.013       0.041       0.353\n",
      "MONEY_1                   -0.3489      0.148     -2.356      0.018      -0.639      -0.059\n",
      "NORP_1                    -0.0920      0.047     -1.960      0.050      -0.184   -7.94e-06\n",
      "ORDINAL_1                 -0.1857      0.095     -1.956      0.050      -0.372       0.000\n",
      "ORG_1                     -0.2194      0.029     -7.565      0.000      -0.276      -0.163\n",
      "PERCENT_1                 -0.2406      0.227     -1.062      0.288      -0.685       0.204\n",
      "PERSON_1                  -0.0569      0.037     -1.538      0.124      -0.129       0.016\n",
      "PRODUCT_1                 -0.1075      0.082     -1.314      0.189      -0.268       0.053\n",
      "QUANTITY_1                 0.0100      0.099      0.101      0.920      -0.184       0.204\n",
      "TIME_1                    -0.2219      0.125     -1.779      0.075      -0.467       0.023\n",
      "WORK_OF_ART_1             -0.1728      0.091     -1.901      0.057      -0.351       0.005\n",
      "CARDINAL_2                -0.0250      0.037     -0.667      0.505      -0.098       0.048\n",
      "DATE_2                    -0.1193      0.041     -2.946      0.003      -0.199      -0.040\n",
      "EVENT_2                    0.1124      0.124      0.908      0.364      -0.130       0.355\n",
      "FAC_2                     -0.3231      0.183     -1.763      0.078      -0.682       0.036\n",
      "GPE_2                     -0.1535      0.032     -4.742      0.000      -0.217      -0.090\n",
      "LANGUAGE_2                 0.0357      0.110      0.324      0.746      -0.180       0.252\n",
      "LAW_2                     -0.0728      0.236     -0.308      0.758      -0.535       0.390\n",
      "LOC_2                     -0.2050      0.079     -2.606      0.009      -0.359      -0.051\n",
      "MONEY_2                   -0.1366      0.156     -0.877      0.381      -0.442       0.169\n",
      "NORP_2                    -0.1394      0.047     -2.938      0.003      -0.232      -0.046\n",
      "ORDINAL_2                 -0.2497      0.093     -2.679      0.007      -0.432      -0.067\n",
      "ORG_2                     -0.1556      0.028     -5.501      0.000      -0.211      -0.100\n",
      "PERCENT_2                 -0.1363      0.193     -0.707      0.480      -0.514       0.242\n",
      "PERSON_2                  -0.0810      0.037     -2.167      0.030      -0.154      -0.008\n",
      "PRODUCT_2                 -0.1847      0.082     -2.256      0.024      -0.345      -0.024\n",
      "QUANTITY_2                 0.0003      0.104      0.003      0.997      -0.204       0.205\n",
      "TIME_2                    -0.0951      0.125     -0.758      0.448      -0.341       0.151\n",
      "WORK_OF_ART_2             -0.2954      0.090     -3.280      0.001      -0.472      -0.119\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "lm = sm.Logit(y, x)\n",
    "result = lm.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (323164,50) and (81126,100) not aligned: 50 (dim 1) != 81126 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-bcc02c09bf79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'question1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'question2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/laurentiusblindow/.virtualenvs/aml-kaggle/lib/python2.7/site-packages/statsmodels/discrete/discrete_model.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, params, exog, linear)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (323164,50) and (81126,100) not aligned: 50 (dim 1) != 81126 (dim 0)"
     ]
    }
   ],
   "source": [
    "lm.predict(df_test.drop(['test_id', 'question1', 'question2'], axis=1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeatures = 50\n",
    "\n",
    "y = df_train['is_duplicate'].values\n",
    "X = df_train.drop(['id', 'question1', 'question2', 'is_duplicate'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(units=200, activation='relu', input_shape=(nfeatures,)))\n",
    "nn.add(layers.Dense(units=50, activation='relu'))\n",
    "nn.add(layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 215442 samples, validate on 107722 samples\n",
      "Epoch 1/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0154 - acc: 0.9943 - val_loss: 0.9187 - val_acc: 0.8902\n",
      "Epoch 2/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0157 - acc: 0.9943 - val_loss: 0.9182 - val_acc: 0.8903\n",
      "Epoch 3/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0154 - acc: 0.9943 - val_loss: 0.8938 - val_acc: 0.8912\n",
      "Epoch 4/100\n",
      "215442/215442 [==============================] - 4s 17us/step - loss: 0.0154 - acc: 0.9942 - val_loss: 0.9584 - val_acc: 0.8919\n",
      "Epoch 5/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0157 - acc: 0.9943 - val_loss: 0.8495 - val_acc: 0.8903\n",
      "Epoch 6/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0152 - acc: 0.9944 - val_loss: 0.8967 - val_acc: 0.8923\n",
      "Epoch 7/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0155 - acc: 0.9945 - val_loss: 0.9260 - val_acc: 0.8907\n",
      "Epoch 8/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0152 - acc: 0.9944 - val_loss: 0.9220 - val_acc: 0.8915\n",
      "Epoch 9/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0157 - acc: 0.9942 - val_loss: 0.8886 - val_acc: 0.8913\n",
      "Epoch 10/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0152 - acc: 0.9944 - val_loss: 0.9033 - val_acc: 0.8905\n",
      "Epoch 11/100\n",
      "215442/215442 [==============================] - 3s 12us/step - loss: 0.0153 - acc: 0.9944 - val_loss: 0.8969 - val_acc: 0.8901\n",
      "Epoch 12/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0154 - acc: 0.9943 - val_loss: 0.9564 - val_acc: 0.8910\n",
      "Epoch 13/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0154 - acc: 0.9943 - val_loss: 0.9421 - val_acc: 0.8911\n",
      "Epoch 14/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0150 - acc: 0.9944 - val_loss: 0.9093 - val_acc: 0.8915\n",
      "Epoch 15/100\n",
      "215442/215442 [==============================] - 2s 11us/step - loss: 0.0153 - acc: 0.9943 - val_loss: 0.9571 - val_acc: 0.8904\n",
      "Epoch 16/100\n",
      "215442/215442 [==============================] - 2s 11us/step - loss: 0.0151 - acc: 0.9944 - val_loss: 0.8726 - val_acc: 0.8915\n",
      "Epoch 17/100\n",
      "215442/215442 [==============================] - 3s 12us/step - loss: 0.0149 - acc: 0.9945 - val_loss: 0.8969 - val_acc: 0.8913\n",
      "Epoch 18/100\n",
      "215442/215442 [==============================] - 2s 11us/step - loss: 0.0150 - acc: 0.9945 - val_loss: 0.9583 - val_acc: 0.8911\n",
      "Epoch 19/100\n",
      "215442/215442 [==============================] - 2s 11us/step - loss: 0.0150 - acc: 0.9944 - val_loss: 0.9235 - val_acc: 0.8905\n",
      "Epoch 20/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0149 - acc: 0.9944 - val_loss: 0.9103 - val_acc: 0.8907\n",
      "Epoch 21/100\n",
      "215442/215442 [==============================] - 4s 18us/step - loss: 0.0150 - acc: 0.9944 - val_loss: 0.9956 - val_acc: 0.8907\n",
      "Epoch 22/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0151 - acc: 0.9944 - val_loss: 0.9447 - val_acc: 0.8909\n",
      "Epoch 23/100\n",
      "215442/215442 [==============================] - 3s 12us/step - loss: 0.0150 - acc: 0.9944 - val_loss: 0.9758 - val_acc: 0.8913\n",
      "Epoch 24/100\n",
      "215442/215442 [==============================] - 5s 21us/step - loss: 0.0149 - acc: 0.9945 - val_loss: 0.9338 - val_acc: 0.8911\n",
      "Epoch 25/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0148 - acc: 0.9946 - val_loss: 0.9868 - val_acc: 0.8901\n",
      "Epoch 26/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0148 - acc: 0.9945 - val_loss: 0.9609 - val_acc: 0.8906\n",
      "Epoch 27/100\n",
      "215442/215442 [==============================] - 2s 11us/step - loss: 0.0148 - acc: 0.9945 - val_loss: 0.9848 - val_acc: 0.8901\n",
      "Epoch 28/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0147 - acc: 0.9946 - val_loss: 0.9662 - val_acc: 0.8914\n",
      "Epoch 29/100\n",
      "215442/215442 [==============================] - 3s 16us/step - loss: 0.0148 - acc: 0.9945 - val_loss: 0.9381 - val_acc: 0.8901\n",
      "Epoch 30/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0148 - acc: 0.9946 - val_loss: 0.9717 - val_acc: 0.8911\n",
      "Epoch 31/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0148 - acc: 0.9944 - val_loss: 0.9513 - val_acc: 0.8903\n",
      "Epoch 32/100\n",
      "215442/215442 [==============================] - 2s 11us/step - loss: 0.0148 - acc: 0.9946 - val_loss: 0.9271 - val_acc: 0.8913\n",
      "Epoch 33/100\n",
      "215442/215442 [==============================] - 2s 11us/step - loss: 0.0148 - acc: 0.9946 - val_loss: 0.9752 - val_acc: 0.8909\n",
      "Epoch 34/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0147 - acc: 0.9945 - val_loss: 0.9506 - val_acc: 0.8905\n",
      "Epoch 35/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0149 - acc: 0.9946 - val_loss: 0.9547 - val_acc: 0.8899\n",
      "Epoch 36/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0147 - acc: 0.9946 - val_loss: 1.0466 - val_acc: 0.8905\n",
      "Epoch 37/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0145 - acc: 0.9946 - val_loss: 1.0012 - val_acc: 0.8909\n",
      "Epoch 38/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0146 - acc: 0.9947 - val_loss: 0.9943 - val_acc: 0.8911\n",
      "Epoch 39/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0148 - acc: 0.9946 - val_loss: 1.0013 - val_acc: 0.8914\n",
      "Epoch 40/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0143 - acc: 0.9947 - val_loss: 0.9827 - val_acc: 0.8911\n",
      "Epoch 41/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0146 - acc: 0.9945 - val_loss: 0.9735 - val_acc: 0.8915\n",
      "Epoch 42/100\n",
      "215442/215442 [==============================] - 4s 18us/step - loss: 0.0145 - acc: 0.9947 - val_loss: 0.9290 - val_acc: 0.8917\n",
      "Epoch 43/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0145 - acc: 0.9947 - val_loss: 0.9777 - val_acc: 0.8910\n",
      "Epoch 44/100\n",
      "215442/215442 [==============================] - 3s 16us/step - loss: 0.0148 - acc: 0.9947 - val_loss: 0.9117 - val_acc: 0.8906\n",
      "Epoch 45/100\n",
      "215442/215442 [==============================] - 4s 17us/step - loss: 0.0143 - acc: 0.9947 - val_loss: 0.9587 - val_acc: 0.8913\n",
      "Epoch 46/100\n",
      "215442/215442 [==============================] - 4s 17us/step - loss: 0.0143 - acc: 0.9946 - val_loss: 0.9978 - val_acc: 0.8915\n",
      "Epoch 47/100\n",
      "215442/215442 [==============================] - 4s 17us/step - loss: 0.0146 - acc: 0.9946 - val_loss: 1.0143 - val_acc: 0.8905\n",
      "Epoch 48/100\n",
      "215442/215442 [==============================] - 3s 12us/step - loss: 0.0144 - acc: 0.9946 - val_loss: 0.9130 - val_acc: 0.8914\n",
      "Epoch 49/100\n",
      "215442/215442 [==============================] - 2s 11us/step - loss: 0.0142 - acc: 0.9947 - val_loss: 0.9897 - val_acc: 0.8913\n",
      "Epoch 50/100\n",
      "215442/215442 [==============================] - 3s 12us/step - loss: 0.0143 - acc: 0.9947 - val_loss: 0.9892 - val_acc: 0.8915\n",
      "Epoch 51/100\n",
      "215442/215442 [==============================] - 2s 11us/step - loss: 0.0140 - acc: 0.9948 - val_loss: 0.9919 - val_acc: 0.8910\n",
      "Epoch 52/100\n",
      "215442/215442 [==============================] - 2s 11us/step - loss: 0.0141 - acc: 0.9949 - val_loss: 0.9930 - val_acc: 0.8908\n",
      "Epoch 53/100\n",
      "215442/215442 [==============================] - 2s 11us/step - loss: 0.0142 - acc: 0.9948 - val_loss: 1.0328 - val_acc: 0.8898\n",
      "Epoch 54/100\n",
      "215442/215442 [==============================] - 2s 11us/step - loss: 0.0142 - acc: 0.9947 - val_loss: 1.0304 - val_acc: 0.8907\n",
      "Epoch 55/100\n",
      "215442/215442 [==============================] - 2s 11us/step - loss: 0.0142 - acc: 0.9947 - val_loss: 1.0366 - val_acc: 0.8907\n",
      "Epoch 56/100\n",
      "215442/215442 [==============================] - 2s 10us/step - loss: 0.0141 - acc: 0.9947 - val_loss: 0.9931 - val_acc: 0.8911\n",
      "Epoch 57/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0141 - acc: 0.9947 - val_loss: 1.0562 - val_acc: 0.8897\n",
      "Epoch 58/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0141 - acc: 0.9949 - val_loss: 1.0418 - val_acc: 0.8915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0141 - acc: 0.9948 - val_loss: 1.0591 - val_acc: 0.8907\n",
      "Epoch 60/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0141 - acc: 0.9948 - val_loss: 1.0116 - val_acc: 0.8905\n",
      "Epoch 61/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0140 - acc: 0.9948 - val_loss: 1.0018 - val_acc: 0.8905\n",
      "Epoch 62/100\n",
      "215442/215442 [==============================] - 4s 16us/step - loss: 0.0141 - acc: 0.9948 - val_loss: 0.9356 - val_acc: 0.8912\n",
      "Epoch 63/100\n",
      "215442/215442 [==============================] - 3s 16us/step - loss: 0.0140 - acc: 0.9949 - val_loss: 0.9958 - val_acc: 0.8912\n",
      "Epoch 64/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0139 - acc: 0.9948 - val_loss: 1.0088 - val_acc: 0.8914\n",
      "Epoch 65/100\n",
      "215442/215442 [==============================] - 3s 16us/step - loss: 0.0140 - acc: 0.9947 - val_loss: 0.9983 - val_acc: 0.8910\n",
      "Epoch 66/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0141 - acc: 0.9947 - val_loss: 0.9929 - val_acc: 0.8913\n",
      "Epoch 67/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0139 - acc: 0.9949 - val_loss: 0.9879 - val_acc: 0.8913\n",
      "Epoch 68/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0140 - acc: 0.9949 - val_loss: 0.9403 - val_acc: 0.8904\n",
      "Epoch 69/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0139 - acc: 0.9948 - val_loss: 1.0511 - val_acc: 0.8902\n",
      "Epoch 70/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0140 - acc: 0.9949 - val_loss: 1.0743 - val_acc: 0.8910\n",
      "Epoch 71/100\n",
      "215442/215442 [==============================] - 4s 16us/step - loss: 0.0137 - acc: 0.9948 - val_loss: 1.0321 - val_acc: 0.8904\n",
      "Epoch 72/100\n",
      "215442/215442 [==============================] - 3s 16us/step - loss: 0.0139 - acc: 0.9947 - val_loss: 1.0225 - val_acc: 0.8915\n",
      "Epoch 73/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0137 - acc: 0.9949 - val_loss: 1.0125 - val_acc: 0.8908\n",
      "Epoch 74/100\n",
      "215442/215442 [==============================] - 3s 16us/step - loss: 0.0139 - acc: 0.9949 - val_loss: 0.9800 - val_acc: 0.8903\n",
      "Epoch 75/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0136 - acc: 0.9950 - val_loss: 1.0223 - val_acc: 0.8912\n",
      "Epoch 76/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0137 - acc: 0.9949 - val_loss: 1.0123 - val_acc: 0.8914\n",
      "Epoch 77/100\n",
      "215442/215442 [==============================] - 4s 17us/step - loss: 0.0138 - acc: 0.9949 - val_loss: 1.0496 - val_acc: 0.8911\n",
      "Epoch 78/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0142 - acc: 0.9948 - val_loss: 1.0080 - val_acc: 0.8917\n",
      "Epoch 79/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0135 - acc: 0.9950 - val_loss: 1.0148 - val_acc: 0.8910\n",
      "Epoch 80/100\n",
      "215442/215442 [==============================] - 3s 16us/step - loss: 0.0136 - acc: 0.9949 - val_loss: 1.0647 - val_acc: 0.8910\n",
      "Epoch 81/100\n",
      "215442/215442 [==============================] - 3s 16us/step - loss: 0.0136 - acc: 0.9949 - val_loss: 1.0330 - val_acc: 0.8904\n",
      "Epoch 82/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0135 - acc: 0.9950 - val_loss: 1.0236 - val_acc: 0.8918\n",
      "Epoch 83/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0138 - acc: 0.9949 - val_loss: 1.0446 - val_acc: 0.8911\n",
      "Epoch 84/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0136 - acc: 0.9949 - val_loss: 1.0573 - val_acc: 0.8914\n",
      "Epoch 85/100\n",
      "215442/215442 [==============================] - 3s 16us/step - loss: 0.0136 - acc: 0.9949 - val_loss: 1.0140 - val_acc: 0.8908\n",
      "Epoch 86/100\n",
      "215442/215442 [==============================] - 3s 13us/step - loss: 0.0134 - acc: 0.9951 - val_loss: 1.0389 - val_acc: 0.8908\n",
      "Epoch 87/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0133 - acc: 0.9949 - val_loss: 1.0404 - val_acc: 0.8916\n",
      "Epoch 88/100\n",
      "215442/215442 [==============================] - 3s 16us/step - loss: 0.0134 - acc: 0.9951 - val_loss: 1.0493 - val_acc: 0.8911\n",
      "Epoch 89/100\n",
      "215442/215442 [==============================] - 3s 16us/step - loss: 0.0137 - acc: 0.9950 - val_loss: 1.0726 - val_acc: 0.8901\n",
      "Epoch 90/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0136 - acc: 0.9950 - val_loss: 1.0453 - val_acc: 0.8907\n",
      "Epoch 91/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0133 - acc: 0.9949 - val_loss: 1.1569 - val_acc: 0.8904\n",
      "Epoch 92/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0133 - acc: 0.9951 - val_loss: 1.0275 - val_acc: 0.8908\n",
      "Epoch 93/100\n",
      "215442/215442 [==============================] - 4s 17us/step - loss: 0.0131 - acc: 0.9951 - val_loss: 1.0520 - val_acc: 0.8913\n",
      "Epoch 94/100\n",
      "215442/215442 [==============================] - 3s 16us/step - loss: 0.0134 - acc: 0.9950 - val_loss: 1.0712 - val_acc: 0.8901\n",
      "Epoch 95/100\n",
      "215442/215442 [==============================] - 5s 21us/step - loss: 0.0136 - acc: 0.9950 - val_loss: 1.0135 - val_acc: 0.8914\n",
      "Epoch 96/100\n",
      "215442/215442 [==============================] - 3s 15us/step - loss: 0.0131 - acc: 0.9952 - val_loss: 1.0465 - val_acc: 0.8914\n",
      "Epoch 97/100\n",
      "215442/215442 [==============================] - 4s 16us/step - loss: 0.0135 - acc: 0.9950 - val_loss: 1.0011 - val_acc: 0.8912\n",
      "Epoch 98/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0132 - acc: 0.9951 - val_loss: 1.0200 - val_acc: 0.8904\n",
      "Epoch 99/100\n",
      "215442/215442 [==============================] - 3s 16us/step - loss: 0.0131 - acc: 0.9951 - val_loss: 1.0927 - val_acc: 0.8921\n",
      "Epoch 100/100\n",
      "215442/215442 [==============================] - 3s 14us/step - loss: 0.0132 - acc: 0.9951 - val_loss: 1.0465 - val_acc: 0.8914\n"
     ]
    }
   ],
   "source": [
    "hist = nn.fit(X, y, epochs=100, verbose=1, batch_size=1000, validation_split = 1/3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nn.predict_classes(df_test.drop(['test_id', 'question1', 'question2'], axis=1).values)\n",
    "build_results_set(df_test, y_pred, 'nn_binary_classification3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Generating weights\n",
      "INFO:root:Saved weights to ../models/nn-classification-200-50-densemodel\n",
      "INFO:root:Saved model configs to ../models/nn-classification-200-50-denseconfig.json\n"
     ]
    }
   ],
   "source": [
    "save_model(network, '../models/nn-classification-200-50-dense/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['is_duplicate']\n",
    "X = df_train.drop(['id', 'question1', 'question2', 'is_duplicate'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel='linear', C=1, gamma=1) \n",
    "# there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml-kaggle",
   "language": "python",
   "name": "aml-kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
